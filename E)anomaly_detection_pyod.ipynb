{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bE2zDUq3K-M"
      },
      "source": [
        "# Anomaly Detection using PyOD\n",
        "\n",
        "## Overview\n",
        "This notebook demonstrates anomaly detection using the PyOD (Python Outlier Detection) library. PyOD provides a comprehensive collection of outlier detection algorithms for both univariate and multivariate data.\n",
        "\n",
        "## Key Concepts\n",
        "- **Anomaly (Outlier)**: Data points that deviate significantly from the majority\n",
        "- **Univariate Detection**: Detecting anomalies in single variable data\n",
        "- **Multivariate Detection**: Detecting anomalies considering multiple variables simultaneously\n",
        "\n",
        "## PyOD Algorithms Used\n",
        "1. **Isolation Forest (IForest)**: Tree-based isolation of anomalies\n",
        "2. **Local Outlier Factor (LOF)**: Density-based local anomaly detection\n",
        "3. **One-Class SVM (OCSVM)**: SVM-based novelty detection\n",
        "4. **K-Nearest Neighbors (KNN)**: Distance-based anomaly detection\n",
        "5. **AutoEncoder**: Deep learning-based reconstruction error\n",
        "\n",
        "## Author\n",
        "Created for Machine Learning Course Assignment\n",
        "\n",
        "## References\n",
        "- [PyOD Documentation](https://pyod.readthedocs.io/)\n",
        "- [Anomaly Detection in Time Series](https://neptune.ai/blog/anomaly-detection-in-time-series)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8umpfwR3K-Q"
      },
      "source": [
        "## 1. Install and Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c3eqs7PI3K-S"
      },
      "outputs": [],
      "source": [
        "# Install PyOD if not already installed\n",
        "!pip install pyod --quiet\n",
        "!pip install suod --quiet  # For faster parallel processing\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.metrics import roc_auc_score, precision_recall_curve, average_precision_score\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seed and plotting style\n",
        "np.random.seed(42)\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "print(\"Base libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qg5xb7id3K-U"
      },
      "outputs": [],
      "source": [
        "# Import PyOD algorithms\n",
        "from pyod.models.iforest import IForest\n",
        "from pyod.models.lof import LOF\n",
        "from pyod.models.ocsvm import OCSVM\n",
        "from pyod.models.knn import KNN\n",
        "from pyod.models.hbos import HBOS\n",
        "from pyod.models.pca import PCA as PCA_OD\n",
        "from pyod.models.copod import COPOD\n",
        "from pyod.models.ecod import ECOD\n",
        "from pyod.utils.data import generate_data\n",
        "from pyod.utils.example import visualize\n",
        "\n",
        "print(\"PyOD algorithms imported successfully!\")\n",
        "import pyod\n",
        "print(f\"PyOD version: {pyod.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtJT0XSY3K-V"
      },
      "source": [
        "## 2. Generate Synthetic Data with Anomalies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nkBC318O3K-W"
      },
      "outputs": [],
      "source": [
        "# Generate synthetic data with outliers using PyOD\n",
        "contamination = 0.1  # 10% outliers\n",
        "n_train = 500\n",
        "n_test = 200\n",
        "\n",
        "# Generate training and test data\n",
        "X_train, X_test, y_train, y_test = generate_data(\n",
        "    n_train=n_train,\n",
        "    n_test=n_test,\n",
        "    n_features=2,\n",
        "    contamination=contamination,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Training set: {X_train.shape}\")\n",
        "print(f\"Test set: {X_test.shape}\")\n",
        "print(f\"Contamination rate: {contamination*100}%\")\n",
        "print(f\"Outliers in training: {y_train.sum()}\")\n",
        "print(f\"Outliers in test: {y_test.sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGt956vm3K-X"
      },
      "outputs": [],
      "source": [
        "# Visualize the synthetic data\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Training data\n",
        "axes[0].scatter(X_train[y_train == 0, 0], X_train[y_train == 0, 1],\n",
        "                c='blue', alpha=0.5, s=30, label='Normal')\n",
        "axes[0].scatter(X_train[y_train == 1, 0], X_train[y_train == 1, 1],\n",
        "                c='red', alpha=0.8, s=80, marker='x', linewidths=2, label='Anomaly')\n",
        "axes[0].set_xlabel('Feature 1')\n",
        "axes[0].set_ylabel('Feature 2')\n",
        "axes[0].set_title(f'Training Data (n={n_train})')\n",
        "axes[0].legend()\n",
        "\n",
        "# Test data\n",
        "axes[1].scatter(X_test[y_test == 0, 0], X_test[y_test == 0, 1],\n",
        "                c='blue', alpha=0.5, s=30, label='Normal')\n",
        "axes[1].scatter(X_test[y_test == 1, 0], X_test[y_test == 1, 1],\n",
        "                c='red', alpha=0.8, s=80, marker='x', linewidths=2, label='Anomaly')\n",
        "axes[1].set_xlabel('Feature 1')\n",
        "axes[1].set_ylabel('Feature 2')\n",
        "axes[1].set_title(f'Test Data (n={n_test})')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.suptitle('Synthetic Data with Anomalies', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErGMhhOg3K-Y"
      },
      "source": [
        "## 3. Univariate Anomaly Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZMriWbe3K-Z"
      },
      "outputs": [],
      "source": [
        "# Generate univariate time series data with anomalies\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generate normal data with seasonal pattern\n",
        "n_points = 500\n",
        "time = np.arange(n_points)\n",
        "seasonal = 10 * np.sin(2 * np.pi * time / 50)\n",
        "trend = 0.02 * time\n",
        "noise = np.random.normal(0, 1, n_points)\n",
        "normal_data = seasonal + trend + noise\n",
        "\n",
        "# Add point anomalies\n",
        "data_with_anomalies = normal_data.copy()\n",
        "anomaly_indices = [50, 120, 200, 300, 350, 420, 480]\n",
        "for idx in anomaly_indices:\n",
        "    data_with_anomalies[idx] += np.random.choice([-1, 1]) * np.random.uniform(15, 25)\n",
        "\n",
        "# Create labels\n",
        "y_univariate = np.zeros(n_points)\n",
        "y_univariate[anomaly_indices] = 1\n",
        "\n",
        "# Visualize\n",
        "plt.figure(figsize=(14, 5))\n",
        "plt.plot(time, data_with_anomalies, 'b-', alpha=0.7, label='Time Series')\n",
        "plt.scatter(anomaly_indices, data_with_anomalies[anomaly_indices],\n",
        "            c='red', s=100, marker='o', label='True Anomalies', zorder=5)\n",
        "plt.xlabel('Time')\n",
        "plt.ylabel('Value')\n",
        "plt.title('Univariate Time Series with Point Anomalies')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Total points: {n_points}\")\n",
        "print(f\"Number of anomalies: {len(anomaly_indices)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1v1dT4HW3K-b"
      },
      "outputs": [],
      "source": [
        "# Apply anomaly detection algorithms to univariate data\n",
        "# Reshape data for PyOD (requires 2D input)\n",
        "X_univariate = data_with_anomalies.reshape(-1, 1)\n",
        "\n",
        "# Initialize detectors\n",
        "detectors = {\n",
        "    'Isolation Forest': IForest(contamination=0.02, random_state=42),\n",
        "    'Local Outlier Factor': LOF(contamination=0.02, n_neighbors=20),\n",
        "    'One-Class SVM': OCSVM(contamination=0.02),\n",
        "    'KNN': KNN(contamination=0.02, n_neighbors=10),\n",
        "    'HBOS': HBOS(contamination=0.02),\n",
        "    'COPOD': COPOD(contamination=0.02)\n",
        "}\n",
        "\n",
        "# Fit and predict\n",
        "univariate_results = {}\n",
        "for name, detector in detectors.items():\n",
        "    detector.fit(X_univariate)\n",
        "    predictions = detector.predict(X_univariate)\n",
        "    scores = detector.decision_function(X_univariate)\n",
        "\n",
        "    # Calculate metrics\n",
        "    if y_univariate.sum() > 0:  # If we have true labels\n",
        "        auc = roc_auc_score(y_univariate, scores)\n",
        "        ap = average_precision_score(y_univariate, scores)\n",
        "    else:\n",
        "        auc, ap = 0, 0\n",
        "\n",
        "    univariate_results[name] = {\n",
        "        'predictions': predictions,\n",
        "        'scores': scores,\n",
        "        'auc': auc,\n",
        "        'ap': ap\n",
        "    }\n",
        "    print(f\"{name}: AUC = {auc:.3f}, AP = {ap:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tl-5b1DW3K-d"
      },
      "outputs": [],
      "source": [
        "# Visualize anomaly detection results for univariate data\n",
        "fig, axes = plt.subplots(3, 2, figsize=(16, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, (name, result) in enumerate(univariate_results.items()):\n",
        "    # Plot time series\n",
        "    axes[idx].plot(time, data_with_anomalies, 'b-', alpha=0.5, label='Data')\n",
        "\n",
        "    # Plot true anomalies\n",
        "    axes[idx].scatter(anomaly_indices, data_with_anomalies[anomaly_indices],\n",
        "                      c='green', s=150, marker='o', alpha=0.5, label='True Anomalies')\n",
        "\n",
        "    # Plot detected anomalies\n",
        "    detected_idx = np.where(result['predictions'] == 1)[0]\n",
        "    axes[idx].scatter(detected_idx, data_with_anomalies[detected_idx],\n",
        "                      c='red', s=80, marker='x', linewidths=2, label='Detected')\n",
        "\n",
        "    axes[idx].set_xlabel('Time')\n",
        "    axes[idx].set_ylabel('Value')\n",
        "    axes[idx].set_title(f\"{name}\\nAUC: {result['auc']:.3f}, AP: {result['ap']:.3f}\")\n",
        "    axes[idx].legend(loc='upper left', fontsize=8)\n",
        "    axes[idx].grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('Univariate Anomaly Detection Comparison', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usowErzH3K-d"
      },
      "source": [
        "## 4. Multivariate Anomaly Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjvCAOQL3K-e"
      },
      "outputs": [],
      "source": [
        "# Train and evaluate multiple detectors on multivariate data\n",
        "multivariate_detectors = {\n",
        "    'Isolation Forest': IForest(contamination=contamination, random_state=42),\n",
        "    'LOF': LOF(contamination=contamination, n_neighbors=20),\n",
        "    'One-Class SVM': OCSVM(contamination=contamination),\n",
        "    'KNN': KNN(contamination=contamination, n_neighbors=10),\n",
        "    'HBOS': HBOS(contamination=contamination),\n",
        "    'PCA': PCA_OD(contamination=contamination),\n",
        "    'COPOD': COPOD(contamination=contamination),\n",
        "    'ECOD': ECOD(contamination=contamination)\n",
        "}\n",
        "\n",
        "multivariate_results = {}\n",
        "\n",
        "print(\"Multivariate Anomaly Detection Results:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for name, detector in multivariate_detectors.items():\n",
        "    # Train on training data\n",
        "    detector.fit(X_train)\n",
        "\n",
        "    # Predict on test data\n",
        "    y_pred = detector.predict(X_test)\n",
        "    scores = detector.decision_function(X_test)\n",
        "\n",
        "    # Calculate metrics\n",
        "    auc = roc_auc_score(y_test, scores)\n",
        "    ap = average_precision_score(y_test, scores)\n",
        "\n",
        "    multivariate_results[name] = {\n",
        "        'predictions': y_pred,\n",
        "        'scores': scores,\n",
        "        'auc': auc,\n",
        "        'ap': ap\n",
        "    }\n",
        "\n",
        "    print(f\"{name:20s}: AUC = {auc:.4f}, AP = {ap:.4f}\")\n",
        "\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JavKAP1n3K-f"
      },
      "outputs": [],
      "source": [
        "# Visualize results for top 4 models\n",
        "# Sort by AUC\n",
        "sorted_models = sorted(multivariate_results.items(), key=lambda x: x[1]['auc'], reverse=True)[:4]\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, (name, result) in enumerate(sorted_models):\n",
        "    y_pred = result['predictions']\n",
        "\n",
        "    # True negatives (normal correctly classified)\n",
        "    tn_mask = (y_test == 0) & (y_pred == 0)\n",
        "    # True positives (anomalies correctly detected)\n",
        "    tp_mask = (y_test == 1) & (y_pred == 1)\n",
        "    # False positives (normal classified as anomaly)\n",
        "    fp_mask = (y_test == 0) & (y_pred == 1)\n",
        "    # False negatives (anomalies missed)\n",
        "    fn_mask = (y_test == 1) & (y_pred == 0)\n",
        "\n",
        "    axes[idx].scatter(X_test[tn_mask, 0], X_test[tn_mask, 1], c='blue',\n",
        "                      alpha=0.4, s=30, label='True Negative')\n",
        "    axes[idx].scatter(X_test[tp_mask, 0], X_test[tp_mask, 1], c='green',\n",
        "                      alpha=0.8, s=100, marker='o', label='True Positive')\n",
        "    axes[idx].scatter(X_test[fp_mask, 0], X_test[fp_mask, 1], c='orange',\n",
        "                      alpha=0.8, s=80, marker='s', label='False Positive')\n",
        "    axes[idx].scatter(X_test[fn_mask, 0], X_test[fn_mask, 1], c='red',\n",
        "                      alpha=0.8, s=100, marker='x', linewidths=2, label='False Negative')\n",
        "\n",
        "    axes[idx].set_xlabel('Feature 1')\n",
        "    axes[idx].set_ylabel('Feature 2')\n",
        "    axes[idx].set_title(f\"{name}\\nAUC: {result['auc']:.4f}, AP: {result['ap']:.4f}\")\n",
        "    axes[idx].legend(loc='upper right', fontsize=8)\n",
        "\n",
        "plt.suptitle('Top 4 Anomaly Detection Models (Test Set)', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXd2Y0E_3K-g"
      },
      "source": [
        "## 5. ROC and Precision-Recall Curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJJ3FwwJ3K-g"
      },
      "outputs": [],
      "source": [
        "# Plot ROC curves for all models\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "colors = plt.cm.tab10(np.linspace(0, 1, len(multivariate_results)))\n",
        "\n",
        "# ROC Curve\n",
        "for (name, result), color in zip(multivariate_results.items(), colors):\n",
        "    fpr, tpr, _ = roc_curve(y_test, result['scores'])\n",
        "    axes[0].plot(fpr, tpr, color=color, linewidth=2,\n",
        "                 label=f\"{name} (AUC={result['auc']:.3f})\")\n",
        "\n",
        "axes[0].plot([0, 1], [0, 1], 'k--', linewidth=1)\n",
        "axes[0].set_xlabel('False Positive Rate')\n",
        "axes[0].set_ylabel('True Positive Rate')\n",
        "axes[0].set_title('ROC Curves')\n",
        "axes[0].legend(loc='lower right', fontsize=8)\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Precision-Recall Curve\n",
        "for (name, result), color in zip(multivariate_results.items(), colors):\n",
        "    precision, recall, _ = precision_recall_curve(y_test, result['scores'])\n",
        "    axes[1].plot(recall, precision, color=color, linewidth=2,\n",
        "                 label=f\"{name} (AP={result['ap']:.3f})\")\n",
        "\n",
        "axes[1].set_xlabel('Recall')\n",
        "axes[1].set_ylabel('Precision')\n",
        "axes[1].set_title('Precision-Recall Curves')\n",
        "axes[1].legend(loc='upper right', fontsize=8)\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('Model Performance Comparison', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cR7Iu5J3K-h"
      },
      "source": [
        "## 6. Anomaly Scores Distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K0XHg7a83K-h"
      },
      "outputs": [],
      "source": [
        "# Visualize anomaly score distributions\n",
        "fig, axes = plt.subplots(2, 4, figsize=(16, 8))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, (name, result) in enumerate(multivariate_results.items()):\n",
        "    scores = result['scores']\n",
        "\n",
        "    # Plot distribution for normal and anomaly points\n",
        "    normal_scores = scores[y_test == 0]\n",
        "    anomaly_scores = scores[y_test == 1]\n",
        "\n",
        "    axes[idx].hist(normal_scores, bins=30, alpha=0.5, color='blue', label='Normal', density=True)\n",
        "    axes[idx].hist(anomaly_scores, bins=30, alpha=0.5, color='red', label='Anomaly', density=True)\n",
        "    axes[idx].set_xlabel('Anomaly Score')\n",
        "    axes[idx].set_ylabel('Density')\n",
        "    axes[idx].set_title(f'{name}')\n",
        "    axes[idx].legend(fontsize=8)\n",
        "\n",
        "plt.suptitle('Anomaly Score Distributions by Class', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nGood separation between distributions indicates better anomaly detection.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1pzQZdFh3K-h"
      },
      "source": [
        "## 7. Real-World Use Case: Credit Card Fraud Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cO8joqW3K-h"
      },
      "outputs": [],
      "source": [
        "# Simulate credit card transaction data\n",
        "np.random.seed(42)\n",
        "\n",
        "n_normal = 2000\n",
        "n_fraud = 50\n",
        "\n",
        "# Normal transactions (clustered)\n",
        "normal_amount = np.random.exponential(50, n_normal)  # Average transaction ~$50\n",
        "normal_frequency = np.random.normal(10, 3, n_normal)  # ~10 transactions per month\n",
        "normal_time = np.random.uniform(8, 22, n_normal)  # Regular hours\n",
        "\n",
        "# Fraudulent transactions (unusual patterns)\n",
        "fraud_amount = np.random.exponential(500, n_fraud)  # Much higher amounts\n",
        "fraud_frequency = np.random.normal(40, 10, n_fraud)  # Very high frequency\n",
        "fraud_time = np.random.uniform(0, 24, n_fraud)  # Any time including unusual hours\n",
        "\n",
        "# Combine data\n",
        "X_fraud = np.vstack([\n",
        "    np.column_stack([normal_amount, normal_frequency, normal_time]),\n",
        "    np.column_stack([fraud_amount, fraud_frequency, fraud_time])\n",
        "])\n",
        "\n",
        "y_fraud = np.concatenate([np.zeros(n_normal), np.ones(n_fraud)])\n",
        "\n",
        "# Shuffle\n",
        "shuffle_idx = np.random.permutation(len(y_fraud))\n",
        "X_fraud = X_fraud[shuffle_idx]\n",
        "y_fraud = y_fraud[shuffle_idx]\n",
        "\n",
        "# Create DataFrame\n",
        "fraud_df = pd.DataFrame(X_fraud, columns=['Amount', 'Frequency', 'Hour'])\n",
        "fraud_df['Label'] = y_fraud.astype(int)\n",
        "\n",
        "print(\"Credit Card Transaction Dataset:\")\n",
        "print(fraud_df.describe())\n",
        "print(f\"\\nFraud rate: {y_fraud.sum()/len(y_fraud)*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jjm0-eYn3K-i"
      },
      "outputs": [],
      "source": [
        "# Visualize the fraud dataset\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "features = ['Amount', 'Frequency', 'Hour']\n",
        "for idx, feat in enumerate(features):\n",
        "    normal_data = fraud_df[fraud_df['Label'] == 0][feat]\n",
        "    fraud_data = fraud_df[fraud_df['Label'] == 1][feat]\n",
        "\n",
        "    axes[idx].hist(normal_data, bins=30, alpha=0.5, color='blue', label='Normal', density=True)\n",
        "    axes[idx].hist(fraud_data, bins=30, alpha=0.5, color='red', label='Fraud', density=True)\n",
        "    axes[idx].set_xlabel(feat)\n",
        "    axes[idx].set_ylabel('Density')\n",
        "    axes[idx].set_title(f'{feat} Distribution')\n",
        "    axes[idx].legend()\n",
        "\n",
        "plt.suptitle('Credit Card Transaction Features', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sv5IiuE83K-i"
      },
      "outputs": [],
      "source": [
        "# Apply anomaly detection to fraud data\n",
        "# Preprocess\n",
        "scaler = StandardScaler()\n",
        "X_fraud_scaled = scaler.fit_transform(X_fraud)\n",
        "\n",
        "# Split data\n",
        "X_train_fraud, X_test_fraud, y_train_fraud, y_test_fraud = train_test_split(\n",
        "    X_fraud_scaled, y_fraud, test_size=0.3, random_state=42, stratify=y_fraud\n",
        ")\n",
        "\n",
        "# Calculate contamination from training data\n",
        "fraud_contamination = y_train_fraud.sum() / len(y_train_fraud)\n",
        "\n",
        "# Define detectors\n",
        "fraud_detectors = {\n",
        "    'Isolation Forest': IForest(contamination=fraud_contamination, random_state=42),\n",
        "    'LOF': LOF(contamination=fraud_contamination, n_neighbors=20),\n",
        "    'COPOD': COPOD(contamination=fraud_contamination),\n",
        "    'ECOD': ECOD(contamination=fraud_contamination)\n",
        "}\n",
        "\n",
        "# Train and evaluate\n",
        "print(\"Fraud Detection Results:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "fraud_results = {}\n",
        "for name, detector in fraud_detectors.items():\n",
        "    detector.fit(X_train_fraud)\n",
        "    y_pred = detector.predict(X_test_fraud)\n",
        "    scores = detector.decision_function(X_test_fraud)\n",
        "\n",
        "    auc = roc_auc_score(y_test_fraud, scores)\n",
        "    ap = average_precision_score(y_test_fraud, scores)\n",
        "\n",
        "    fraud_results[name] = {'predictions': y_pred, 'scores': scores, 'auc': auc, 'ap': ap}\n",
        "    print(f\"{name:20s}: AUC = {auc:.4f}, AP = {ap:.4f}\")\n",
        "\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BsCYCV2_3K-j"
      },
      "outputs": [],
      "source": [
        "# Detailed evaluation for best model\n",
        "best_model = max(fraud_results.items(), key=lambda x: x[1]['auc'])\n",
        "print(f\"\\nBest Model: {best_model[0]}\")\n",
        "print(f\"AUC: {best_model[1]['auc']:.4f}\")\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test_fraud, best_model[1]['predictions'],\n",
        "                           target_names=['Normal', 'Fraud']))\n",
        "\n",
        "# Confusion Matrix\n",
        "cm = confusion_matrix(y_test_fraud, best_model[1]['predictions'])\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Normal', 'Fraud'], yticklabels=['Normal', 'Fraud'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title(f'Confusion Matrix - {best_model[0]}')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWb5lo9e3K-j"
      },
      "source": [
        "## 8. Ensemble Anomaly Detection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CNFMH76s3K-j"
      },
      "outputs": [],
      "source": [
        "# Combine multiple detectors for ensemble prediction\n",
        "from pyod.models.combination import average, maximization, aom, moa\n",
        "\n",
        "# Get scores from all models\n",
        "all_scores = np.column_stack([result['scores'] for result in multivariate_results.values()])\n",
        "\n",
        "# Different combination methods\n",
        "ensemble_methods = {\n",
        "    'Average': average(all_scores),\n",
        "    'Maximum': maximization(all_scores),\n",
        "    'AOM (Average of Maximum)': aom(all_scores, n_buckets=4),\n",
        "    'MOA (Maximum of Average)': moa(all_scores, n_buckets=4)\n",
        "}\n",
        "\n",
        "print(\"Ensemble Anomaly Detection Results:\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "for name, scores in ensemble_methods.items():\n",
        "    auc = roc_auc_score(y_test, scores)\n",
        "    ap = average_precision_score(y_test, scores)\n",
        "    print(f\"{name:25s}: AUC = {auc:.4f}, AP = {ap:.4f}\")\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(\"\\nEnsemble methods often outperform individual detectors!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXtIn44X3K-k"
      },
      "source": [
        "## 9. Quality Metrics Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbfDI8Ix3K-k"
      },
      "outputs": [],
      "source": [
        "# Create comprehensive metrics summary\n",
        "metrics_summary = []\n",
        "\n",
        "for name, result in multivariate_results.items():\n",
        "    y_pred = result['predictions']\n",
        "    y_scores = result['scores']\n",
        "\n",
        "    # Calculate various metrics\n",
        "    cm = confusion_matrix(y_test, y_pred)\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
        "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    metrics_summary.append({\n",
        "        'Model': name,\n",
        "        'AUC-ROC': result['auc'],\n",
        "        'Average Precision': result['ap'],\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-Score': f1,\n",
        "        'True Positives': tp,\n",
        "        'False Positives': fp\n",
        "    })\n",
        "\n",
        "metrics_df = pd.DataFrame(metrics_summary)\n",
        "metrics_df = metrics_df.sort_values('AUC-ROC', ascending=False).reset_index(drop=True)\n",
        "\n",
        "print(\"\\nAnomaly Detection Quality Metrics Summary:\")\n",
        "print(\"=\"*100)\n",
        "print(metrics_df.to_string(index=False))\n",
        "print(\"=\"*100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l_sFBES13K-l"
      },
      "outputs": [],
      "source": [
        "# Visualize metrics comparison\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Bar chart for AUC and AP\n",
        "x = np.arange(len(metrics_df))\n",
        "width = 0.35\n",
        "\n",
        "axes[0].bar(x - width/2, metrics_df['AUC-ROC'], width, label='AUC-ROC', color='steelblue')\n",
        "axes[0].bar(x + width/2, metrics_df['Average Precision'], width, label='Average Precision', color='coral')\n",
        "axes[0].set_xlabel('Model')\n",
        "axes[0].set_ylabel('Score')\n",
        "axes[0].set_title('AUC-ROC vs Average Precision')\n",
        "axes[0].set_xticks(x)\n",
        "axes[0].set_xticklabels(metrics_df['Model'], rotation=45, ha='right')\n",
        "axes[0].legend()\n",
        "axes[0].set_ylim([0, 1])\n",
        "\n",
        "# Precision vs Recall scatter\n",
        "axes[1].scatter(metrics_df['Recall'], metrics_df['Precision'], s=100, c='steelblue', edgecolors='black')\n",
        "for i, model in enumerate(metrics_df['Model']):\n",
        "    axes[1].annotate(model, (metrics_df['Recall'].iloc[i], metrics_df['Precision'].iloc[i]),\n",
        "                     xytext=(5, 5), textcoords='offset points', fontsize=8)\n",
        "axes[1].set_xlabel('Recall')\n",
        "axes[1].set_ylabel('Precision')\n",
        "axes[1].set_title('Precision vs Recall Trade-off')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pNBkFqwa3K-m"
      },
      "source": [
        "## 10. Summary and Conclusions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a709GUwa3K-m"
      },
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"ANOMALY DETECTION WITH PyOD - SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\n1. ALGORITHMS USED:\")\n",
        "print(\"   - Isolation Forest: Tree-based isolation\")\n",
        "print(\"   - LOF: Local density-based detection\")\n",
        "print(\"   - One-Class SVM: Boundary-based detection\")\n",
        "print(\"   - KNN: Distance-based detection\")\n",
        "print(\"   - HBOS: Histogram-based detection\")\n",
        "print(\"   - COPOD: Copula-based detection\")\n",
        "print(\"   - ECOD: Empirical CDF-based detection\")\n",
        "\n",
        "print(\"\\n2. USE CASES DEMONSTRATED:\")\n",
        "print(\"   - Univariate time series anomaly detection\")\n",
        "print(\"   - Multivariate point anomaly detection\")\n",
        "print(\"   - Credit card fraud detection (real-world simulation)\")\n",
        "print(\"   - Ensemble anomaly detection\")\n",
        "\n",
        "print(\"\\n3. QUALITY METRICS USED:\")\n",
        "print(\"   - AUC-ROC: Area Under ROC Curve\")\n",
        "print(\"   - Average Precision: Precision-Recall AUC\")\n",
        "print(\"   - Precision: Correctly identified anomalies / Total detected\")\n",
        "print(\"   - Recall: Correctly identified anomalies / Total anomalies\")\n",
        "print(\"   - F1-Score: Harmonic mean of Precision and Recall\")\n",
        "\n",
        "print(\"\\n4. KEY FINDINGS:\")\n",
        "best_model_name = metrics_df.iloc[0]['Model']\n",
        "best_auc = metrics_df.iloc[0]['AUC-ROC']\n",
        "print(f\"   - Best performing model: {best_model_name} (AUC: {best_auc:.4f})\")\n",
        "print(\"   - Ensemble methods can improve detection performance\")\n",
        "print(\"   - Different algorithms suit different data characteristics\")\n",
        "\n",
        "print(\"\\n5. RECOMMENDATIONS:\")\n",
        "print(\"   - Use multiple algorithms and compare results\")\n",
        "print(\"   - Consider ensemble methods for robust detection\")\n",
        "print(\"   - Tune contamination parameter based on domain knowledge\")\n",
        "print(\"   - Evaluate using multiple metrics, not just AUC\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLJa1PaO3K-n"
      },
      "source": [
        "## References\n",
        "\n",
        "1. Zhao, Y., Nasrullah, Z., & Li, Z. (2019). PyOD: A Python Toolbox for Scalable Outlier Detection. JMLR.\n",
        "2. Liu, F. T., Ting, K. M., & Zhou, Z. H. (2008). Isolation forest. ICDM.\n",
        "3. Breunig, M. M., et al. (2000). LOF: Identifying density-based local outliers. SIGMOD.\n",
        "4. PyOD Documentation: https://pyod.readthedocs.io/\n",
        "5. Neptune.ai - Anomaly Detection in Time Series: https://neptune.ai/blog/anomaly-detection-in-time-series"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}