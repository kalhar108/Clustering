{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wvahop8X3Ucz"
      },
      "source": [
        "# Document Clustering with LLM Embeddings\n",
        "\n",
        "## Overview\n",
        "This notebook demonstrates document clustering using state-of-the-art LLM embeddings. We'll explore how modern embedding models can capture semantic meaning and enable effective document clustering.\n",
        "\n",
        "## Embedding Models Used\n",
        "1. **Sentence-Transformers**: Open-source sentence embeddings\n",
        "2. **all-MiniLM-L6-v2**: Fast and efficient transformer model\n",
        "3. **all-mpnet-base-v2**: Higher quality embeddings\n",
        "\n",
        "## Clustering Approaches\n",
        "- K-Means on embeddings\n",
        "- Hierarchical clustering\n",
        "- HDBSCAN for density-based clustering\n",
        "\n",
        "## Author\n",
        "Created for Machine Learning Course Assignment\n",
        "\n",
        "## References\n",
        "- [Sentence-Transformers](https://www.sbert.net/)\n",
        "- [LLM Cluster](https://github.com/simonw/llm-cluster)\n",
        "- [UKPLab Sentence Transformers Examples](https://github.com/UKPLab/sentence-transformers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mg59K7em3Uc5"
      },
      "source": [
        "## 1. Install and Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5IH_Kzm3Uc6"
      },
      "outputs": [],
      "source": [
        "# Install required libraries\n",
        "!pip install sentence-transformers --quiet\n",
        "!pip install hdbscan --quiet\n",
        "!pip install umap-learn --quiet\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_score, adjusted_rand_score, normalized_mutual_info_score\n",
        "from sklearn.metrics import calinski_harabasz_score, davies_bouldin_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.manifold import TSNE\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seed and plotting style\n",
        "np.random.seed(42)\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "print(\"Base libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FhleDqK_3Uc8"
      },
      "outputs": [],
      "source": [
        "# Import embedding and clustering libraries\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import hdbscan\n",
        "import umap\n",
        "\n",
        "print(\"Sentence-Transformers and clustering libraries imported!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwN3_-bR3Uc9"
      },
      "source": [
        "## 2. Create Sample Document Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQi9bgIU3Uc-"
      },
      "outputs": [],
      "source": [
        "# Create a sample dataset with documents from different categories\n",
        "documents = [\n",
        "    # Technology (Category 0)\n",
        "    \"The new smartphone features an advanced AI chip for better performance.\",\n",
        "    \"Machine learning algorithms are transforming how we process data.\",\n",
        "    \"Cloud computing enables businesses to scale their infrastructure easily.\",\n",
        "    \"Cybersecurity threats continue to evolve with new attack vectors.\",\n",
        "    \"The latest software update includes important security patches.\",\n",
        "    \"Artificial intelligence is revolutionizing healthcare diagnostics.\",\n",
        "    \"Programming languages like Python are essential for data science.\",\n",
        "    \"Virtual reality headsets are becoming more affordable and powerful.\",\n",
        "    \"Quantum computing promises to solve complex problems faster.\",\n",
        "    \"The tech industry is investing heavily in renewable energy solutions.\",\n",
        "\n",
        "    # Sports (Category 1)\n",
        "    \"The basketball team won the championship after an exciting final game.\",\n",
        "    \"Soccer players are training hard for the upcoming World Cup.\",\n",
        "    \"The tennis tournament attracted thousands of spectators worldwide.\",\n",
        "    \"Olympic athletes are preparing for the summer games in Paris.\",\n",
        "    \"The football quarterback threw three touchdown passes in the game.\",\n",
        "    \"Marathon runners completed the race despite challenging weather.\",\n",
        "    \"The golf tournament featured some of the world's best players.\",\n",
        "    \"Swimming records were broken at the international competition.\",\n",
        "    \"Baseball season tickets are selling out quickly this year.\",\n",
        "    \"The hockey team celebrated their first championship in decades.\",\n",
        "\n",
        "    # Finance (Category 2)\n",
        "    \"Stock market indices reached new all-time highs this quarter.\",\n",
        "    \"Interest rates remain stable despite economic uncertainty.\",\n",
        "    \"Cryptocurrency investments have become increasingly popular.\",\n",
        "    \"The central bank announced new monetary policy measures.\",\n",
        "    \"Investment portfolios should be diversified for risk management.\",\n",
        "    \"Corporate earnings reports exceeded analyst expectations.\",\n",
        "    \"The bond market is showing signs of increased volatility.\",\n",
        "    \"Inflation rates are affecting consumer purchasing power.\",\n",
        "    \"Mutual funds offer a way to invest in diverse securities.\",\n",
        "    \"The financial sector is adopting blockchain technology.\",\n",
        "\n",
        "    # Health (Category 3)\n",
        "    \"Regular exercise improves cardiovascular health and mental wellbeing.\",\n",
        "    \"A balanced diet is essential for maintaining good health.\",\n",
        "    \"Medical researchers are developing new treatments for cancer.\",\n",
        "    \"Vaccination programs have significantly reduced disease rates.\",\n",
        "    \"Mental health awareness is increasing in workplaces and schools.\",\n",
        "    \"Sleep quality affects cognitive function and immune system.\",\n",
        "    \"Hospitals are implementing new patient care technologies.\",\n",
        "    \"Preventive healthcare can reduce long-term medical costs.\",\n",
        "    \"Nutrition science reveals the importance of micronutrients.\",\n",
        "    \"Telemedicine is making healthcare more accessible globally.\",\n",
        "\n",
        "    # Environment (Category 4)\n",
        "    \"Climate change is causing more frequent extreme weather events.\",\n",
        "    \"Renewable energy sources are becoming more cost-effective.\",\n",
        "    \"Deforestation threatens biodiversity in tropical regions.\",\n",
        "    \"Ocean pollution is affecting marine ecosystems worldwide.\",\n",
        "    \"Electric vehicles are helping reduce carbon emissions.\",\n",
        "    \"Sustainable farming practices protect soil and water resources.\",\n",
        "    \"Wildlife conservation efforts are crucial for endangered species.\",\n",
        "    \"Recycling programs help reduce waste in landfills.\",\n",
        "    \"Air quality improvements are linked to public health benefits.\",\n",
        "    \"Green building standards promote energy-efficient construction.\"\n",
        "]\n",
        "\n",
        "# True labels\n",
        "categories = (\n",
        "    ['Technology'] * 10 +\n",
        "    ['Sports'] * 10 +\n",
        "    ['Finance'] * 10 +\n",
        "    ['Health'] * 10 +\n",
        "    ['Environment'] * 10\n",
        ")\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame({\n",
        "    'document': documents,\n",
        "    'category': categories\n",
        "})\n",
        "\n",
        "# Encode labels\n",
        "le = LabelEncoder()\n",
        "y_true = le.fit_transform(categories)\n",
        "\n",
        "print(f\"Total documents: {len(documents)}\")\n",
        "print(f\"Categories: {le.classes_}\")\n",
        "print(f\"\\nSample documents:\")\n",
        "print(df.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44zW0-kr3UdB"
      },
      "source": [
        "## 3. Generate Document Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NrGPQeFR3UdD"
      },
      "outputs": [],
      "source": [
        "# Load different embedding models\n",
        "print(\"Loading embedding models...\")\n",
        "\n",
        "# Model 1: all-MiniLM-L6-v2 (fast and efficient)\n",
        "model_minilm = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "print(\"✓ Loaded all-MiniLM-L6-v2\")\n",
        "\n",
        "# Model 2: all-mpnet-base-v2 (higher quality)\n",
        "model_mpnet = SentenceTransformer('all-mpnet-base-v2')\n",
        "print(\"✓ Loaded all-mpnet-base-v2\")\n",
        "\n",
        "print(\"\\nModels loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FKpgEM_93UdF"
      },
      "outputs": [],
      "source": [
        "# Generate embeddings\n",
        "print(\"Generating embeddings...\")\n",
        "\n",
        "# MiniLM embeddings\n",
        "embeddings_minilm = model_minilm.encode(documents, show_progress_bar=True)\n",
        "print(f\"MiniLM embeddings shape: {embeddings_minilm.shape}\")\n",
        "\n",
        "# MPNet embeddings\n",
        "embeddings_mpnet = model_mpnet.encode(documents, show_progress_bar=True)\n",
        "print(f\"MPNet embeddings shape: {embeddings_mpnet.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJp50BCz3UdG"
      },
      "source": [
        "## 4. Visualize Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09HIpDSu3UdH"
      },
      "outputs": [],
      "source": [
        "# Use UMAP for dimensionality reduction and visualization\n",
        "print(\"Reducing dimensions with UMAP...\")\n",
        "\n",
        "# UMAP for MiniLM\n",
        "umap_reducer = umap.UMAP(n_components=2, random_state=42, n_neighbors=10, min_dist=0.1)\n",
        "embeddings_minilm_2d = umap_reducer.fit_transform(embeddings_minilm)\n",
        "\n",
        "# UMAP for MPNet\n",
        "embeddings_mpnet_2d = umap_reducer.fit_transform(embeddings_mpnet)\n",
        "\n",
        "print(\"Dimensionality reduction complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLZlBbpO3UdH"
      },
      "outputs": [],
      "source": [
        "# Visualize embeddings\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "colors = {'Technology': 'blue', 'Sports': 'green', 'Finance': 'red',\n",
        "          'Health': 'purple', 'Environment': 'orange'}\n",
        "\n",
        "# MiniLM embeddings\n",
        "for cat in le.classes_:\n",
        "    mask = np.array(categories) == cat\n",
        "    axes[0].scatter(embeddings_minilm_2d[mask, 0], embeddings_minilm_2d[mask, 1],\n",
        "                    c=colors[cat], label=cat, alpha=0.7, s=60, edgecolors='k')\n",
        "axes[0].set_xlabel('UMAP Dimension 1')\n",
        "axes[0].set_ylabel('UMAP Dimension 2')\n",
        "axes[0].set_title('all-MiniLM-L6-v2 Embeddings')\n",
        "axes[0].legend()\n",
        "\n",
        "# MPNet embeddings\n",
        "for cat in le.classes_:\n",
        "    mask = np.array(categories) == cat\n",
        "    axes[1].scatter(embeddings_mpnet_2d[mask, 0], embeddings_mpnet_2d[mask, 1],\n",
        "                    c=colors[cat], label=cat, alpha=0.7, s=60, edgecolors='k')\n",
        "axes[1].set_xlabel('UMAP Dimension 1')\n",
        "axes[1].set_ylabel('UMAP Dimension 2')\n",
        "axes[1].set_title('all-mpnet-base-v2 Embeddings')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.suptitle('Document Embeddings Visualization (UMAP)', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKXn3Dk03UdI"
      },
      "source": [
        "## 5. K-Means Clustering on Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSdM69xK3UdI"
      },
      "outputs": [],
      "source": [
        "# Apply K-Means clustering\n",
        "n_clusters = 5\n",
        "\n",
        "# K-Means on MiniLM embeddings\n",
        "kmeans_minilm = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "labels_minilm = kmeans_minilm.fit_predict(embeddings_minilm)\n",
        "\n",
        "# K-Means on MPNet embeddings\n",
        "kmeans_mpnet = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "labels_mpnet = kmeans_mpnet.fit_predict(embeddings_mpnet)\n",
        "\n",
        "print(\"K-Means clustering complete!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gcc6xg-I3UdJ"
      },
      "outputs": [],
      "source": [
        "# Evaluate clustering quality\n",
        "def evaluate_clustering(embeddings, labels_pred, y_true, model_name):\n",
        "    ari = adjusted_rand_score(y_true, labels_pred)\n",
        "    nmi = normalized_mutual_info_score(y_true, labels_pred)\n",
        "    sil = silhouette_score(embeddings, labels_pred)\n",
        "    ch = calinski_harabasz_score(embeddings, labels_pred)\n",
        "    db = davies_bouldin_score(embeddings, labels_pred)\n",
        "\n",
        "    return {\n",
        "        'Model': model_name,\n",
        "        'ARI': ari,\n",
        "        'NMI': nmi,\n",
        "        'Silhouette': sil,\n",
        "        'Calinski-Harabasz': ch,\n",
        "        'Davies-Bouldin': db\n",
        "    }\n",
        "\n",
        "results = []\n",
        "results.append(evaluate_clustering(embeddings_minilm, labels_minilm, y_true, 'MiniLM + K-Means'))\n",
        "results.append(evaluate_clustering(embeddings_mpnet, labels_mpnet, y_true, 'MPNet + K-Means'))\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"K-Means Clustering Results:\")\n",
        "print(\"=\"*70)\n",
        "print(results_df.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybvtldlg3UdJ"
      },
      "outputs": [],
      "source": [
        "# Visualize clustering results\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
        "\n",
        "# MiniLM clustering\n",
        "scatter1 = axes[0].scatter(embeddings_minilm_2d[:, 0], embeddings_minilm_2d[:, 1],\n",
        "                           c=labels_minilm, cmap='viridis', alpha=0.7, s=60, edgecolors='k')\n",
        "axes[0].set_xlabel('UMAP Dimension 1')\n",
        "axes[0].set_ylabel('UMAP Dimension 2')\n",
        "axes[0].set_title(f'MiniLM + K-Means\\nARI: {results[0][\"ARI\"]:.3f}')\n",
        "plt.colorbar(scatter1, ax=axes[0], label='Cluster')\n",
        "\n",
        "# MPNet clustering\n",
        "scatter2 = axes[1].scatter(embeddings_mpnet_2d[:, 0], embeddings_mpnet_2d[:, 1],\n",
        "                           c=labels_mpnet, cmap='viridis', alpha=0.7, s=60, edgecolors='k')\n",
        "axes[1].set_xlabel('UMAP Dimension 1')\n",
        "axes[1].set_ylabel('UMAP Dimension 2')\n",
        "axes[1].set_title(f'MPNet + K-Means\\nARI: {results[1][\"ARI\"]:.3f}')\n",
        "plt.colorbar(scatter2, ax=axes[1], label='Cluster')\n",
        "\n",
        "plt.suptitle('K-Means Clustering Results', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKVtUso33UdK"
      },
      "source": [
        "## 6. Hierarchical Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLXqQ_mj3UdL"
      },
      "outputs": [],
      "source": [
        "# Apply Hierarchical Clustering\n",
        "hclust_minilm = AgglomerativeClustering(n_clusters=5, linkage='ward')\n",
        "labels_hclust_minilm = hclust_minilm.fit_predict(embeddings_minilm)\n",
        "\n",
        "hclust_mpnet = AgglomerativeClustering(n_clusters=5, linkage='ward')\n",
        "labels_hclust_mpnet = hclust_mpnet.fit_predict(embeddings_mpnet)\n",
        "\n",
        "# Evaluate\n",
        "results.append(evaluate_clustering(embeddings_minilm, labels_hclust_minilm, y_true, 'MiniLM + Hierarchical'))\n",
        "results.append(evaluate_clustering(embeddings_mpnet, labels_hclust_mpnet, y_true, 'MPNet + Hierarchical'))\n",
        "\n",
        "print(\"Hierarchical Clustering Results:\")\n",
        "print(\"=\"*70)\n",
        "print(pd.DataFrame(results[2:]).to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KglNsKw_3UdL"
      },
      "outputs": [],
      "source": [
        "# Create dendrogram for document clustering\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage\n",
        "\n",
        "# Use MPNet embeddings for dendrogram\n",
        "Z = linkage(embeddings_mpnet, method='ward')\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "\n",
        "# Create short labels\n",
        "short_labels = [f\"{cat[:4]}_{i}\" for i, cat in enumerate(categories)]\n",
        "\n",
        "dendrogram(Z, labels=short_labels, leaf_rotation=90, leaf_font_size=8,\n",
        "           color_threshold=25)\n",
        "plt.title('Hierarchical Clustering Dendrogram (MPNet Embeddings)', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Document')\n",
        "plt.ylabel('Distance')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4M2PYhxH3UdL"
      },
      "source": [
        "## 7. HDBSCAN Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jIAM1b13UdL"
      },
      "outputs": [],
      "source": [
        "# Apply HDBSCAN (density-based clustering)\n",
        "hdbscan_minilm = hdbscan.HDBSCAN(min_cluster_size=5, min_samples=2)\n",
        "labels_hdbscan_minilm = hdbscan_minilm.fit_predict(embeddings_minilm)\n",
        "\n",
        "hdbscan_mpnet = hdbscan.HDBSCAN(min_cluster_size=5, min_samples=2)\n",
        "labels_hdbscan_mpnet = hdbscan_mpnet.fit_predict(embeddings_mpnet)\n",
        "\n",
        "print(f\"HDBSCAN clusters found (MiniLM): {len(set(labels_hdbscan_minilm)) - (1 if -1 in labels_hdbscan_minilm else 0)}\")\n",
        "print(f\"HDBSCAN clusters found (MPNet): {len(set(labels_hdbscan_mpnet)) - (1 if -1 in labels_hdbscan_mpnet else 0)}\")\n",
        "print(f\"Noise points (MiniLM): {(labels_hdbscan_minilm == -1).sum()}\")\n",
        "print(f\"Noise points (MPNet): {(labels_hdbscan_mpnet == -1).sum()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ULGBSkQB3UdM"
      },
      "outputs": [],
      "source": [
        "# Evaluate HDBSCAN (excluding noise points for some metrics)\n",
        "def evaluate_hdbscan(embeddings, labels_pred, y_true, model_name):\n",
        "    # Filter out noise for ARI/NMI calculation\n",
        "    valid_mask = labels_pred >= 0\n",
        "\n",
        "    if valid_mask.sum() > 0 and len(set(labels_pred[valid_mask])) > 1:\n",
        "        ari = adjusted_rand_score(y_true[valid_mask], labels_pred[valid_mask])\n",
        "        nmi = normalized_mutual_info_score(y_true[valid_mask], labels_pred[valid_mask])\n",
        "        sil = silhouette_score(embeddings[valid_mask], labels_pred[valid_mask])\n",
        "    else:\n",
        "        ari, nmi, sil = 0, 0, 0\n",
        "\n",
        "    n_clusters = len(set(labels_pred)) - (1 if -1 in labels_pred else 0)\n",
        "    n_noise = (labels_pred == -1).sum()\n",
        "\n",
        "    return {\n",
        "        'Model': model_name,\n",
        "        'ARI': ari,\n",
        "        'NMI': nmi,\n",
        "        'Silhouette': sil,\n",
        "        'N Clusters': n_clusters,\n",
        "        'N Noise': n_noise\n",
        "    }\n",
        "\n",
        "hdbscan_results = []\n",
        "hdbscan_results.append(evaluate_hdbscan(embeddings_minilm, labels_hdbscan_minilm, y_true, 'MiniLM + HDBSCAN'))\n",
        "hdbscan_results.append(evaluate_hdbscan(embeddings_mpnet, labels_hdbscan_mpnet, y_true, 'MPNet + HDBSCAN'))\n",
        "\n",
        "print(\"HDBSCAN Clustering Results:\")\n",
        "print(\"=\"*70)\n",
        "print(pd.DataFrame(hdbscan_results).to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9k8Q18mD3UdM"
      },
      "source": [
        "## 8. Finding Optimal Number of Clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vF_jMxuL3UdM"
      },
      "outputs": [],
      "source": [
        "# Elbow method and Silhouette analysis for optimal K\n",
        "k_range = range(2, 10)\n",
        "inertias = []\n",
        "silhouettes = []\n",
        "\n",
        "for k in k_range:\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
        "    labels = kmeans.fit_predict(embeddings_mpnet)\n",
        "    inertias.append(kmeans.inertia_)\n",
        "    silhouettes.append(silhouette_score(embeddings_mpnet, labels))\n",
        "\n",
        "# Plot\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Elbow curve\n",
        "axes[0].plot(k_range, inertias, 'bo-', linewidth=2, markersize=8)\n",
        "axes[0].set_xlabel('Number of Clusters (K)')\n",
        "axes[0].set_ylabel('Inertia')\n",
        "axes[0].set_title('Elbow Method')\n",
        "axes[0].axvline(x=5, color='red', linestyle='--', label='K=5 (True)')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Silhouette curve\n",
        "axes[1].plot(k_range, silhouettes, 'go-', linewidth=2, markersize=8)\n",
        "axes[1].set_xlabel('Number of Clusters (K)')\n",
        "axes[1].set_ylabel('Silhouette Score')\n",
        "axes[1].set_title('Silhouette Analysis')\n",
        "axes[1].axvline(x=5, color='red', linestyle='--', label='K=5 (True)')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.suptitle('Optimal Number of Clusters (MPNet Embeddings)', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "optimal_k = list(k_range)[np.argmax(silhouettes)]\n",
        "print(f\"\\nOptimal K by Silhouette: {optimal_k}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xl6ex7sm3UdM"
      },
      "source": [
        "## 9. Semantic Similarity Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ITOrD8RY3UdM"
      },
      "outputs": [],
      "source": [
        "# Compute cosine similarity between documents\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "similarity_matrix = cosine_similarity(embeddings_mpnet)\n",
        "\n",
        "# Create a heatmap\n",
        "plt.figure(figsize=(12, 10))\n",
        "\n",
        "# Sort documents by category for better visualization\n",
        "sorted_indices = np.argsort(y_true)\n",
        "sorted_similarity = similarity_matrix[sorted_indices][:, sorted_indices]\n",
        "\n",
        "# Create labels\n",
        "sorted_categories = np.array(categories)[sorted_indices]\n",
        "\n",
        "sns.heatmap(sorted_similarity, cmap='RdYlBu_r',\n",
        "            xticklabels=False, yticklabels=False,\n",
        "            vmin=0, vmax=1)\n",
        "\n",
        "# Add category separators\n",
        "category_boundaries = [0, 10, 20, 30, 40, 50]\n",
        "for boundary in category_boundaries[1:-1]:\n",
        "    plt.axhline(y=boundary, color='black', linewidth=2)\n",
        "    plt.axvline(x=boundary, color='black', linewidth=2)\n",
        "\n",
        "plt.title('Document Semantic Similarity Matrix\\n(MPNet Embeddings)', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Documents (sorted by category)')\n",
        "plt.ylabel('Documents (sorted by category)')\n",
        "\n",
        "# Add category labels\n",
        "for i, cat in enumerate(le.classes_):\n",
        "    plt.text(-3, 5 + i*10, cat, fontsize=10, rotation=0, ha='right', va='center')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"The diagonal blocks show high similarity within categories.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjiP_XLK3UdN"
      },
      "source": [
        "## 10. Cluster Interpretation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9VZltJ7T3UdN"
      },
      "outputs": [],
      "source": [
        "# Analyze what each cluster contains\n",
        "df['cluster_kmeans'] = labels_mpnet\n",
        "\n",
        "print(\"Cluster Analysis (MPNet + K-Means):\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for cluster in range(n_clusters):\n",
        "    cluster_docs = df[df['cluster_kmeans'] == cluster]\n",
        "    print(f\"\\nCluster {cluster} ({len(cluster_docs)} documents):\")\n",
        "    print(f\"  Category distribution: {cluster_docs['category'].value_counts().to_dict()}\")\n",
        "    print(f\"  Sample documents:\")\n",
        "    for doc in cluster_docs['document'].head(2):\n",
        "        print(f\"    - {doc[:80]}...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-B8paJr83UdN"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix: True Category vs Predicted Cluster\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_true, labels_mpnet)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=range(5), yticklabels=le.classes_)\n",
        "plt.xlabel('Predicted Cluster')\n",
        "plt.ylabel('True Category')\n",
        "plt.title('Confusion Matrix: Categories vs Clusters (MPNet + K-Means)', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0Kviek93UdN"
      },
      "source": [
        "## 11. Comprehensive Results Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNsLowHD3UdN"
      },
      "outputs": [],
      "source": [
        "# Combine all results\n",
        "all_results = pd.DataFrame(results)\n",
        "\n",
        "print(\"=\"*80)\n",
        "print(\"COMPREHENSIVE DOCUMENT CLUSTERING RESULTS\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\nAll Methods Comparison:\")\n",
        "print(all_results.to_string(index=False))\n",
        "\n",
        "# Best performing method\n",
        "best_method = all_results.loc[all_results['ARI'].idxmax()]\n",
        "print(f\"\\nBest performing method: {best_method['Model']}\")\n",
        "print(f\"ARI: {best_method['ARI']:.4f}, NMI: {best_method['NMI']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g1Z3btaI3UdO"
      },
      "outputs": [],
      "source": [
        "# Visualize results comparison\n",
        "fig, ax = plt.subplots(figsize=(12, 6))\n",
        "\n",
        "x = np.arange(len(all_results))\n",
        "width = 0.25\n",
        "\n",
        "bars1 = ax.bar(x - width, all_results['ARI'], width, label='ARI', color='steelblue')\n",
        "bars2 = ax.bar(x, all_results['NMI'], width, label='NMI', color='coral')\n",
        "bars3 = ax.bar(x + width, all_results['Silhouette'], width, label='Silhouette', color='green')\n",
        "\n",
        "ax.set_xlabel('Method')\n",
        "ax.set_ylabel('Score')\n",
        "ax.set_title('Document Clustering Methods Comparison', fontsize=14, fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(all_results['Model'], rotation=45, ha='right')\n",
        "ax.legend()\n",
        "ax.set_ylim([0, 1])\n",
        "ax.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDnr566y3UdO"
      },
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"DOCUMENT CLUSTERING WITH LLM EMBEDDINGS - SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\n1. EMBEDDING MODELS USED:\")\n",
        "print(\"   - all-MiniLM-L6-v2: Fast, 384-dimensional embeddings\")\n",
        "print(\"   - all-mpnet-base-v2: Higher quality, 768-dimensional embeddings\")\n",
        "\n",
        "print(\"\\n2. CLUSTERING ALGORITHMS:\")\n",
        "print(\"   - K-Means: Partition-based clustering\")\n",
        "print(\"   - Hierarchical: Agglomerative clustering with Ward linkage\")\n",
        "print(\"   - HDBSCAN: Density-based clustering\")\n",
        "\n",
        "print(\"\\n3. QUALITY METRICS:\")\n",
        "print(\"   - Adjusted Rand Index (ARI): Agreement with ground truth\")\n",
        "print(\"   - Normalized Mutual Information (NMI): Information overlap\")\n",
        "print(\"   - Silhouette Score: Cluster cohesion and separation\")\n",
        "print(\"   - Calinski-Harabasz Index: Variance ratio criterion\")\n",
        "print(\"   - Davies-Bouldin Index: Cluster similarity measure\")\n",
        "\n",
        "print(\"\\n4. DATASET:\")\n",
        "print(f\"   - {len(documents)} documents\")\n",
        "print(f\"   - {len(le.classes_)} categories: {', '.join(le.classes_)}\")\n",
        "\n",
        "print(\"\\n5. KEY FINDINGS:\")\n",
        "print(f\"   - Best method: {best_method['Model']}\")\n",
        "print(\"   - LLM embeddings effectively capture semantic meaning\")\n",
        "print(\"   - Documents from same category cluster together\")\n",
        "print(\"   - MPNet provides slightly better embeddings than MiniLM\")\n",
        "\n",
        "print(\"\\n6. RECOMMENDATIONS:\")\n",
        "print(\"   - Use MPNet for higher quality (when speed is not critical)\")\n",
        "print(\"   - Use MiniLM for faster processing (large document sets)\")\n",
        "print(\"   - Visualize with UMAP to verify cluster structure\")\n",
        "print(\"   - Use silhouette analysis to find optimal K\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEnmc1YB3UdP"
      },
      "source": [
        "## References\n",
        "\n",
        "1. Reimers, N., & Gurevych, I. (2019). Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks. EMNLP.\n",
        "2. McInnes, L., & Healy, J. (2017). HDBSCAN: Hierarchical density based clustering. JOSS.\n",
        "3. McInnes, L., Healy, J., & Melville, J. (2018). UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction.\n",
        "4. Sentence-Transformers Documentation: https://www.sbert.net/\n",
        "5. LLM Cluster: https://github.com/simonw/llm-cluster"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}