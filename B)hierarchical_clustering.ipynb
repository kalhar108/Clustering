{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAo02MV73I5p"
      },
      "source": [
        "# Hierarchical Clustering\n",
        "\n",
        "## Overview\n",
        "This notebook demonstrates Hierarchical Clustering, an unsupervised machine learning algorithm that builds a hierarchy of clusters. Unlike K-Means, hierarchical clustering does not require specifying the number of clusters beforehand.\n",
        "\n",
        "## Types of Hierarchical Clustering\n",
        "1. **Agglomerative (Bottom-Up)**: Starts with each data point as its own cluster and merges the closest pairs iteratively\n",
        "2. **Divisive (Top-Down)**: Starts with all data points in one cluster and recursively splits them\n",
        "\n",
        "## Linkage Methods\n",
        "- **Single Linkage**: Minimum distance between clusters\n",
        "- **Complete Linkage**: Maximum distance between clusters\n",
        "- **Average Linkage**: Average distance between all pairs\n",
        "- **Ward's Method**: Minimizes within-cluster variance\n",
        "\n",
        "## Author\n",
        "Created for Machine Learning Course Assignment\n",
        "\n",
        "## References\n",
        "- [Scipy Hierarchical Clustering](https://docs.scipy.org/doc/scipy/reference/cluster.hierarchy.html)\n",
        "- [Scikit-learn Hierarchical Clustering](https://scikit-learn.org/stable/modules/clustering.html#hierarchical-clustering)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bs06XXNQ3I5q"
      },
      "source": [
        "## 1. Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QkGJ4XDp3I5r"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.datasets import make_blobs, load_iris, make_moons\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
        "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster, cophenet\n",
        "from scipy.spatial.distance import pdist\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seed and plotting style\n",
        "np.random.seed(42)\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "print(\"Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRzoVF7a3I5r"
      },
      "source": [
        "## 2. Generate and Visualize Synthetic Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EdDASNwk3I5r"
      },
      "outputs": [],
      "source": [
        "# Generate synthetic clustered data\n",
        "X_blobs, y_blobs = make_blobs(n_samples=300, centers=4, cluster_std=0.6,\n",
        "                               n_features=2, random_state=42)\n",
        "\n",
        "# Generate moon-shaped data (non-globular clusters)\n",
        "X_moons, y_moons = make_moons(n_samples=300, noise=0.05, random_state=42)\n",
        "\n",
        "# Visualize both datasets\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "axes[0].scatter(X_blobs[:, 0], X_blobs[:, 1], c=y_blobs, cmap='viridis',\n",
        "                alpha=0.7, edgecolors='k', s=50)\n",
        "axes[0].set_xlabel('Feature 1')\n",
        "axes[0].set_ylabel('Feature 2')\n",
        "axes[0].set_title('Blob Clusters (Ground Truth)')\n",
        "\n",
        "axes[1].scatter(X_moons[:, 0], X_moons[:, 1], c=y_moons, cmap='viridis',\n",
        "                alpha=0.7, edgecolors='k', s=50)\n",
        "axes[1].set_xlabel('Feature 1')\n",
        "axes[1].set_ylabel('Feature 2')\n",
        "axes[1].set_title('Moon Clusters (Ground Truth)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Blob dataset shape: {X_blobs.shape}\")\n",
        "print(f\"Moon dataset shape: {X_moons.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m171RrMa3I5s"
      },
      "source": [
        "## 3. Understanding Dendrograms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x6UTFbRm3I5s"
      },
      "outputs": [],
      "source": [
        "# Create a smaller subset for clear dendrogram visualization\n",
        "np.random.seed(42)\n",
        "sample_indices = np.random.choice(len(X_blobs), 50, replace=False)\n",
        "X_sample = X_blobs[sample_indices]\n",
        "\n",
        "# Calculate linkage matrix using different methods\n",
        "linkage_methods = ['single', 'complete', 'average', 'ward']\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, method in enumerate(linkage_methods):\n",
        "    Z = linkage(X_sample, method=method)\n",
        "    dendrogram(Z, ax=axes[idx], leaf_rotation=90, leaf_font_size=8)\n",
        "    axes[idx].set_title(f'{method.capitalize()} Linkage Dendrogram', fontsize=12, fontweight='bold')\n",
        "    axes[idx].set_xlabel('Sample Index')\n",
        "    axes[idx].set_ylabel('Distance')\n",
        "\n",
        "plt.suptitle('Comparison of Different Linkage Methods', fontsize=14, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BU-FuGOV3I5s"
      },
      "source": [
        "## 4. Cophenetic Correlation Coefficient\n",
        "\n",
        "The cophenetic correlation coefficient measures how well the dendrogram preserves the pairwise distances between data points. A value close to 1 indicates good preservation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wYzSMG_R3I5t"
      },
      "outputs": [],
      "source": [
        "# Calculate cophenetic correlation for each linkage method\n",
        "print(\"Cophenetic Correlation Coefficients:\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "coph_results = {}\n",
        "for method in linkage_methods:\n",
        "    Z = linkage(X_blobs, method=method)\n",
        "    c, coph_dists = cophenet(Z, pdist(X_blobs))\n",
        "    coph_results[method] = c\n",
        "    print(f\"{method.capitalize()} Linkage: {c:.4f}\")\n",
        "\n",
        "print(\"\\nHigher values indicate better preservation of original distances.\")\n",
        "print(f\"Best method: {max(coph_results, key=coph_results.get).capitalize()} Linkage\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HdPYVvp83I5t"
      },
      "source": [
        "## 5. Agglomerative Clustering with Sklearn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDwYRvFA3I5t"
      },
      "outputs": [],
      "source": [
        "# Apply Agglomerative Clustering with different linkage methods\n",
        "n_clusters = 4\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "results = {}\n",
        "\n",
        "for idx, method in enumerate(linkage_methods):\n",
        "    # Ward linkage requires Euclidean distance\n",
        "    if method == 'ward':\n",
        "        agg_cluster = AgglomerativeClustering(n_clusters=n_clusters, linkage=method)\n",
        "    else:\n",
        "        agg_cluster = AgglomerativeClustering(n_clusters=n_clusters, linkage=method)\n",
        "\n",
        "    labels = agg_cluster.fit_predict(X_blobs)\n",
        "\n",
        "    # Calculate metrics\n",
        "    sil_score = silhouette_score(X_blobs, labels)\n",
        "    ch_score = calinski_harabasz_score(X_blobs, labels)\n",
        "    db_score = davies_bouldin_score(X_blobs, labels)\n",
        "    ari = adjusted_rand_score(y_blobs, labels)\n",
        "\n",
        "    results[method] = {\n",
        "        'labels': labels,\n",
        "        'silhouette': sil_score,\n",
        "        'calinski_harabasz': ch_score,\n",
        "        'davies_bouldin': db_score,\n",
        "        'adjusted_rand': ari\n",
        "    }\n",
        "\n",
        "    # Plot\n",
        "    scatter = axes[idx].scatter(X_blobs[:, 0], X_blobs[:, 1], c=labels,\n",
        "                                 cmap='viridis', alpha=0.7, edgecolors='k', s=50)\n",
        "    axes[idx].set_xlabel('Feature 1')\n",
        "    axes[idx].set_ylabel('Feature 2')\n",
        "    axes[idx].set_title(f'{method.capitalize()} Linkage\\nSilhouette: {sil_score:.3f}, ARI: {ari:.3f}')\n",
        "\n",
        "plt.suptitle('Agglomerative Clustering with Different Linkage Methods',\n",
        "             fontsize=14, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cux9GNI23I5t"
      },
      "outputs": [],
      "source": [
        "# Display metrics comparison\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Linkage Method': [m.capitalize() for m in linkage_methods],\n",
        "    'Silhouette Score': [results[m]['silhouette'] for m in linkage_methods],\n",
        "    'Calinski-Harabasz': [results[m]['calinski_harabasz'] for m in linkage_methods],\n",
        "    'Davies-Bouldin': [results[m]['davies_bouldin'] for m in linkage_methods],\n",
        "    'Adjusted Rand Index': [results[m]['adjusted_rand'] for m in linkage_methods]\n",
        "})\n",
        "\n",
        "print(\"\\nClustering Quality Metrics Comparison:\")\n",
        "print(\"=\"*80)\n",
        "print(metrics_df.to_string(index=False))\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"\\nMetric Interpretation:\")\n",
        "print(\"• Silhouette Score: Higher is better (range: -1 to 1)\")\n",
        "print(\"• Calinski-Harabasz: Higher is better\")\n",
        "print(\"• Davies-Bouldin: Lower is better\")\n",
        "print(\"• Adjusted Rand Index: Higher is better (1.0 = perfect match with ground truth)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaYGm2vx3I5u"
      },
      "source": [
        "## 6. Hierarchical Clustering on Moon-Shaped Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khjr2Gpy3I5u"
      },
      "outputs": [],
      "source": [
        "# Compare different linkage methods on non-globular data\n",
        "fig, axes = plt.subplots(1, 4, figsize=(18, 4))\n",
        "\n",
        "moon_results = {}\n",
        "\n",
        "for idx, method in enumerate(linkage_methods):\n",
        "    agg_cluster = AgglomerativeClustering(n_clusters=2, linkage=method)\n",
        "    labels = agg_cluster.fit_predict(X_moons)\n",
        "\n",
        "    ari = adjusted_rand_score(y_moons, labels)\n",
        "    sil = silhouette_score(X_moons, labels)\n",
        "    moon_results[method] = {'ari': ari, 'silhouette': sil}\n",
        "\n",
        "    axes[idx].scatter(X_moons[:, 0], X_moons[:, 1], c=labels,\n",
        "                      cmap='viridis', alpha=0.7, edgecolors='k', s=50)\n",
        "    axes[idx].set_xlabel('Feature 1')\n",
        "    axes[idx].set_ylabel('Feature 2')\n",
        "    axes[idx].set_title(f'{method.capitalize()}\\nARI: {ari:.3f}')\n",
        "\n",
        "plt.suptitle('Hierarchical Clustering on Moon-Shaped Data', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nNote: Single linkage performs best on non-globular clusters\")\n",
        "print(\"because it can detect elongated cluster shapes.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AiRQ7VtT3I5u"
      },
      "source": [
        "## 7. Cutting the Dendrogram at Different Heights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEeeHZdp3I5u"
      },
      "outputs": [],
      "source": [
        "# Create linkage matrix for full blob dataset\n",
        "Z_ward = linkage(X_blobs, method='ward')\n",
        "\n",
        "# Plot dendrogram with color threshold\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Full dendrogram\n",
        "dendrogram(Z_ward, ax=axes[0], truncate_mode='lastp', p=30,\n",
        "           leaf_rotation=90, leaf_font_size=10, color_threshold=0)\n",
        "axes[0].set_title('Ward Linkage Dendrogram (Truncated)', fontsize=12, fontweight='bold')\n",
        "axes[0].set_xlabel('Sample Index or (Cluster Size)')\n",
        "axes[0].set_ylabel('Distance')\n",
        "\n",
        "# Dendrogram with color threshold to show 4 clusters\n",
        "threshold = 15\n",
        "dendrogram(Z_ward, ax=axes[1], truncate_mode='lastp', p=30,\n",
        "           leaf_rotation=90, leaf_font_size=10, color_threshold=threshold)\n",
        "axes[1].axhline(y=threshold, color='red', linestyle='--', linewidth=2,\n",
        "                label=f'Cut threshold = {threshold}')\n",
        "axes[1].set_title('Dendrogram with Cluster Threshold', fontsize=12, fontweight='bold')\n",
        "axes[1].set_xlabel('Sample Index or (Cluster Size)')\n",
        "axes[1].set_ylabel('Distance')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QPcgyqxt3I5u"
      },
      "outputs": [],
      "source": [
        "# Cut dendrogram at different thresholds\n",
        "thresholds = [5, 10, 15, 25]\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx, thresh in enumerate(thresholds):\n",
        "    labels = fcluster(Z_ward, t=thresh, criterion='distance')\n",
        "    n_clusters_found = len(np.unique(labels))\n",
        "\n",
        "    if n_clusters_found > 1:\n",
        "        sil = silhouette_score(X_blobs, labels)\n",
        "    else:\n",
        "        sil = 0\n",
        "\n",
        "    scatter = axes[idx].scatter(X_blobs[:, 0], X_blobs[:, 1], c=labels,\n",
        "                                 cmap='viridis', alpha=0.7, edgecolors='k', s=50)\n",
        "    axes[idx].set_xlabel('Feature 1')\n",
        "    axes[idx].set_ylabel('Feature 2')\n",
        "    axes[idx].set_title(f'Threshold = {thresh}\\nClusters: {n_clusters_found}, Silhouette: {sil:.3f}')\n",
        "\n",
        "plt.suptitle('Cutting Dendrogram at Different Distance Thresholds',\n",
        "             fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2S9SpiiF3I5u"
      },
      "source": [
        "## 8. Finding Optimal Number of Clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NSFaHcou3I5u"
      },
      "outputs": [],
      "source": [
        "# Calculate metrics for different number of clusters\n",
        "k_range = range(2, 10)\n",
        "silhouette_scores = []\n",
        "ch_scores = []\n",
        "db_scores = []\n",
        "\n",
        "for k in k_range:\n",
        "    agg = AgglomerativeClustering(n_clusters=k, linkage='ward')\n",
        "    labels = agg.fit_predict(X_blobs)\n",
        "\n",
        "    silhouette_scores.append(silhouette_score(X_blobs, labels))\n",
        "    ch_scores.append(calinski_harabasz_score(X_blobs, labels))\n",
        "    db_scores.append(davies_bouldin_score(X_blobs, labels))\n",
        "\n",
        "# Plot metrics\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "axes[0].plot(k_range, silhouette_scores, 'go-', linewidth=2, markersize=8)\n",
        "axes[0].set_xlabel('Number of Clusters')\n",
        "axes[0].set_ylabel('Silhouette Score')\n",
        "axes[0].set_title('Silhouette Score vs K')\n",
        "axes[0].axvline(x=4, color='red', linestyle='--', alpha=0.7, label='Optimal K=4')\n",
        "axes[0].legend()\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "axes[1].plot(k_range, ch_scores, 'bo-', linewidth=2, markersize=8)\n",
        "axes[1].set_xlabel('Number of Clusters')\n",
        "axes[1].set_ylabel('Calinski-Harabasz Index')\n",
        "axes[1].set_title('Calinski-Harabasz Index vs K')\n",
        "axes[1].axvline(x=4, color='red', linestyle='--', alpha=0.7, label='Optimal K=4')\n",
        "axes[1].legend()\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "axes[2].plot(k_range, db_scores, 'ro-', linewidth=2, markersize=8)\n",
        "axes[2].set_xlabel('Number of Clusters')\n",
        "axes[2].set_ylabel('Davies-Bouldin Index')\n",
        "axes[2].set_title('Davies-Bouldin Index vs K')\n",
        "axes[2].axvline(x=4, color='red', linestyle='--', alpha=0.7, label='Optimal K=4')\n",
        "axes[2].legend()\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Find optimal K\n",
        "optimal_k_sil = list(k_range)[np.argmax(silhouette_scores)]\n",
        "optimal_k_ch = list(k_range)[np.argmax(ch_scores)]\n",
        "optimal_k_db = list(k_range)[np.argmin(db_scores)]\n",
        "\n",
        "print(f\"\\nOptimal K by Silhouette Score: {optimal_k_sil}\")\n",
        "print(f\"Optimal K by Calinski-Harabasz Index: {optimal_k_ch}\")\n",
        "print(f\"Optimal K by Davies-Bouldin Index: {optimal_k_db}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "umPix4G93I5v"
      },
      "source": [
        "## 9. Real Dataset: Iris Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "02YWpBk13I5v"
      },
      "outputs": [],
      "source": [
        "# Load and prepare Iris dataset\n",
        "iris = load_iris()\n",
        "X_iris = iris.data\n",
        "y_iris = iris.target\n",
        "feature_names = iris.feature_names\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_iris_scaled = scaler.fit_transform(X_iris)\n",
        "\n",
        "print(f\"Iris dataset shape: {X_iris.shape}\")\n",
        "print(f\"Features: {feature_names}\")\n",
        "print(f\"Number of species: {len(np.unique(y_iris))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cr_X4fUz3I5v"
      },
      "outputs": [],
      "source": [
        "# Apply hierarchical clustering to Iris dataset\n",
        "agg_iris = AgglomerativeClustering(n_clusters=3, linkage='ward')\n",
        "labels_iris = agg_iris.fit_predict(X_iris_scaled)\n",
        "\n",
        "# Calculate metrics\n",
        "sil_iris = silhouette_score(X_iris_scaled, labels_iris)\n",
        "ari_iris = adjusted_rand_score(y_iris, labels_iris)\n",
        "nmi_iris = normalized_mutual_info_score(y_iris, labels_iris)\n",
        "\n",
        "print(\"Iris Clustering Metrics:\")\n",
        "print(f\"  Silhouette Score: {sil_iris:.4f}\")\n",
        "print(f\"  Adjusted Rand Index: {ari_iris:.4f}\")\n",
        "print(f\"  Normalized Mutual Information: {nmi_iris:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oqdk6fgP3I5v"
      },
      "outputs": [],
      "source": [
        "# Visualize Iris clustering\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# True labels\n",
        "scatter1 = axes[0].scatter(X_iris[:, 0], X_iris[:, 1], c=y_iris,\n",
        "                           cmap='viridis', alpha=0.7, edgecolors='k', s=60)\n",
        "axes[0].set_xlabel(feature_names[0])\n",
        "axes[0].set_ylabel(feature_names[1])\n",
        "axes[0].set_title('Iris - True Species Labels')\n",
        "\n",
        "# Hierarchical clustering labels\n",
        "scatter2 = axes[1].scatter(X_iris[:, 0], X_iris[:, 1], c=labels_iris,\n",
        "                           cmap='viridis', alpha=0.7, edgecolors='k', s=60)\n",
        "axes[1].set_xlabel(feature_names[0])\n",
        "axes[1].set_ylabel(feature_names[1])\n",
        "axes[1].set_title(f'Iris - Hierarchical Clustering\\nARI: {ari_iris:.3f}')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgI1MoG23I5v"
      },
      "outputs": [],
      "source": [
        "# Create dendrogram for Iris dataset\n",
        "Z_iris = linkage(X_iris_scaled, method='ward')\n",
        "\n",
        "plt.figure(figsize=(14, 8))\n",
        "dendrogram(Z_iris, truncate_mode='lastp', p=50,\n",
        "           leaf_rotation=90, leaf_font_size=8,\n",
        "           color_threshold=7)\n",
        "plt.axhline(y=7, color='red', linestyle='--', linewidth=2, label='3 Clusters Threshold')\n",
        "plt.xlabel('Sample Index or (Cluster Size)')\n",
        "plt.ylabel('Distance')\n",
        "plt.title('Hierarchical Clustering Dendrogram - Iris Dataset (Ward Linkage)',\n",
        "          fontsize=14, fontweight='bold')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TASg2lD3I5v"
      },
      "source": [
        "## 10. Heatmap with Hierarchical Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEjiWLlq3I5v"
      },
      "outputs": [],
      "source": [
        "# Create a clustered heatmap using seaborn\n",
        "iris_df = pd.DataFrame(X_iris_scaled, columns=feature_names)\n",
        "iris_df['Species'] = iris.target_names[y_iris]\n",
        "\n",
        "# Create clustermap\n",
        "g = sns.clustermap(iris_df.drop('Species', axis=1),\n",
        "                   method='ward',\n",
        "                   cmap='viridis',\n",
        "                   standard_scale=None,\n",
        "                   figsize=(10, 10),\n",
        "                   row_colors=pd.Series(y_iris).map({0: 'red', 1: 'green', 2: 'blue'}),\n",
        "                   dendrogram_ratio=(0.15, 0.15))\n",
        "\n",
        "g.fig.suptitle('Clustered Heatmap of Iris Features', fontsize=14, fontweight='bold', y=1.02)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nRow colors indicate true species: Red=Setosa, Green=Versicolor, Blue=Virginica\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VWsSG_1q3I5v"
      },
      "source": [
        "## 11. Comparison: Hierarchical vs K-Means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-LDV2qVj3I5v"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# Compare hierarchical clustering with K-Means on both datasets\n",
        "datasets = [\n",
        "    (X_blobs, y_blobs, 'Blob Clusters', 4),\n",
        "    (X_moons, y_moons, 'Moon Clusters', 2)\n",
        "]\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "\n",
        "for row, (X, y_true, name, n_clusters) in enumerate(datasets):\n",
        "    # Ground truth\n",
        "    axes[row, 0].scatter(X[:, 0], X[:, 1], c=y_true, cmap='viridis',\n",
        "                         alpha=0.7, edgecolors='k', s=50)\n",
        "    axes[row, 0].set_title(f'{name}\\nGround Truth')\n",
        "    axes[row, 0].set_xlabel('Feature 1')\n",
        "    axes[row, 0].set_ylabel('Feature 2')\n",
        "\n",
        "    # K-Means\n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "    labels_km = kmeans.fit_predict(X)\n",
        "    ari_km = adjusted_rand_score(y_true, labels_km)\n",
        "    axes[row, 1].scatter(X[:, 0], X[:, 1], c=labels_km, cmap='viridis',\n",
        "                         alpha=0.7, edgecolors='k', s=50)\n",
        "    axes[row, 1].set_title(f'K-Means\\nARI: {ari_km:.3f}')\n",
        "    axes[row, 1].set_xlabel('Feature 1')\n",
        "    axes[row, 1].set_ylabel('Feature 2')\n",
        "\n",
        "    # Hierarchical (single linkage for moons, ward for blobs)\n",
        "    linkage_method = 'single' if name == 'Moon Clusters' else 'ward'\n",
        "    agg = AgglomerativeClustering(n_clusters=n_clusters, linkage=linkage_method)\n",
        "    labels_agg = agg.fit_predict(X)\n",
        "    ari_agg = adjusted_rand_score(y_true, labels_agg)\n",
        "    axes[row, 2].scatter(X[:, 0], X[:, 1], c=labels_agg, cmap='viridis',\n",
        "                         alpha=0.7, edgecolors='k', s=50)\n",
        "    axes[row, 2].set_title(f'Hierarchical ({linkage_method})\\nARI: {ari_agg:.3f}')\n",
        "    axes[row, 2].set_xlabel('Feature 1')\n",
        "    axes[row, 2].set_ylabel('Feature 2')\n",
        "\n",
        "plt.suptitle('Comparison: K-Means vs Hierarchical Clustering',\n",
        "             fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nKey Observations:\")\n",
        "print(\"• K-Means works well on globular clusters (blobs)\")\n",
        "print(\"• Hierarchical clustering with single linkage handles non-globular shapes (moons)\")\n",
        "print(\"• Ward linkage works similarly to K-Means for compact clusters\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QInenjW03I5v"
      },
      "source": [
        "## 12. Summary and Conclusions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0_QwWSfG3I5v"
      },
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"HIERARCHICAL CLUSTERING - SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\n1. ALGORITHMS USED:\")\n",
        "print(\"   - Agglomerative (bottom-up) hierarchical clustering\")\n",
        "print(\"   - Multiple linkage methods: single, complete, average, ward\")\n",
        "\n",
        "print(\"\\n2. KEY ADVANTAGES:\")\n",
        "print(\"   - No need to specify number of clusters beforehand\")\n",
        "print(\"   - Produces hierarchical structure (dendrogram)\")\n",
        "print(\"   - Can capture non-globular cluster shapes (single linkage)\")\n",
        "print(\"   - Deterministic (no random initialization)\")\n",
        "\n",
        "print(\"\\n3. LINKAGE METHODS COMPARISON:\")\n",
        "print(\"   - Single: Best for elongated/chain-like clusters\")\n",
        "print(\"   - Complete: Tends to produce compact, equal-sized clusters\")\n",
        "print(\"   - Average: Balanced approach, less sensitive to outliers\")\n",
        "print(\"   - Ward: Minimizes variance, similar to K-Means\")\n",
        "\n",
        "print(\"\\n4. CLUSTERING QUALITY METRICS USED:\")\n",
        "print(\"   - Silhouette Score: Cluster cohesion and separation\")\n",
        "print(\"   - Calinski-Harabasz Index: Between/within cluster variance ratio\")\n",
        "print(\"   - Davies-Bouldin Index: Average cluster similarity\")\n",
        "print(\"   - Adjusted Rand Index: Agreement with ground truth\")\n",
        "print(\"   - Cophenetic Correlation: Dendrogram quality measure\")\n",
        "\n",
        "print(\"\\n5. DATASETS TESTED:\")\n",
        "print(\"   - Synthetic blob clusters (globular)\")\n",
        "print(\"   - Moon-shaped clusters (non-globular)\")\n",
        "print(\"   - Iris dataset (real-world)\")\n",
        "\n",
        "print(\"\\n6. KEY FINDINGS:\")\n",
        "print(\"   - Ward linkage performs best on globular clusters\")\n",
        "print(\"   - Single linkage excels at detecting non-globular patterns\")\n",
        "print(\"   - Dendrogram visualization helps determine optimal cluster count\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lk3I9-r3I5v"
      },
      "source": [
        "## References\n",
        "\n",
        "1. Murtagh, F., & Contreras, P. (2012). Algorithms for hierarchical clustering: an overview. Wiley Interdisciplinary Reviews.\n",
        "2. Ward Jr, J. H. (1963). Hierarchical grouping to optimize an objective function. Journal of the American Statistical Association.\n",
        "3. Scikit-learn documentation: https://scikit-learn.org/stable/modules/clustering.html#hierarchical-clustering\n",
        "4. SciPy documentation: https://docs.scipy.org/doc/scipy/reference/cluster.hierarchy.html"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}