{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtYfw_a63IRD"
      },
      "source": [
        "# K-Means Clustering from Scratch\n",
        "\n",
        "## Overview\n",
        "This notebook implements the K-Means clustering algorithm from scratch in Python. K-Means is one of the most popular unsupervised machine learning algorithms used for partitioning data into K distinct clusters.\n",
        "\n",
        "## Algorithm Steps\n",
        "1. **Initialize** K centroids randomly\n",
        "2. **Assign** each data point to the nearest centroid\n",
        "3. **Update** centroids by computing the mean of all points assigned to each cluster\n",
        "4. **Repeat** steps 2-3 until convergence (centroids don't change significantly)\n",
        "\n",
        "## Author\n",
        "Created for Machine Learning Course Assignment\n",
        "\n",
        "## References\n",
        "- [Python Data Science Handbook - K-Means](https://jakevdp.github.io/PythonDataScienceHandbook/05.11-k-means.html)\n",
        "- [Google ML Clustering Exercise](https://developers.google.com/machine-learning/clustering/programming-exercise)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2I6hNW3h3IRE"
      },
      "source": [
        "## 1. Import Required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GdcPgZe33IRF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_blobs, load_iris\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
        "from sklearn.cluster import KMeans as SklearnKMeans\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "print(\"Libraries imported successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VqjqGaDp3IRF"
      },
      "source": [
        "## 2. K-Means Implementation from Scratch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTho2oXE3IRF"
      },
      "outputs": [],
      "source": [
        "class KMeansFromScratch:\n",
        "    \"\"\"\n",
        "    K-Means Clustering Algorithm Implementation from Scratch\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    n_clusters : int, default=3\n",
        "        The number of clusters to form\n",
        "    max_iters : int, default=300\n",
        "        Maximum number of iterations for a single run\n",
        "    tol : float, default=1e-4\n",
        "        Tolerance for convergence\n",
        "    init : str, default='random'\n",
        "        Initialization method: 'random' or 'kmeans++'\n",
        "    n_init : int, default=10\n",
        "        Number of times the algorithm will be run with different centroid seeds\n",
        "    random_state : int, default=None\n",
        "        Random seed for reproducibility\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, n_clusters=3, max_iters=300, tol=1e-4, init='random',\n",
        "                 n_init=10, random_state=None):\n",
        "        self.n_clusters = n_clusters\n",
        "        self.max_iters = max_iters\n",
        "        self.tol = tol\n",
        "        self.init = init\n",
        "        self.n_init = n_init\n",
        "        self.random_state = random_state\n",
        "\n",
        "        # Attributes set after fitting\n",
        "        self.centroids = None\n",
        "        self.labels_ = None\n",
        "        self.inertia_ = None\n",
        "        self.n_iter_ = None\n",
        "        self.history = []  # Store centroid history for visualization\n",
        "\n",
        "    def _euclidean_distance(self, x1, x2):\n",
        "        \"\"\"Calculate Euclidean distance between two points\"\"\"\n",
        "        return np.sqrt(np.sum((x1 - x2) ** 2, axis=1))\n",
        "\n",
        "    def _initialize_centroids_random(self, X):\n",
        "        \"\"\"Initialize centroids by randomly selecting K data points\"\"\"\n",
        "        n_samples = X.shape[0]\n",
        "        random_indices = np.random.choice(n_samples, self.n_clusters, replace=False)\n",
        "        return X[random_indices].copy()\n",
        "\n",
        "    def _initialize_centroids_kmeans_plus_plus(self, X):\n",
        "        \"\"\"\n",
        "        Initialize centroids using K-Means++ algorithm\n",
        "        This provides smarter initialization for faster convergence\n",
        "        \"\"\"\n",
        "        n_samples = X.shape[0]\n",
        "        centroids = []\n",
        "\n",
        "        # Choose first centroid randomly\n",
        "        first_idx = np.random.randint(n_samples)\n",
        "        centroids.append(X[first_idx])\n",
        "\n",
        "        # Choose remaining centroids\n",
        "        for _ in range(1, self.n_clusters):\n",
        "            # Calculate distances from each point to nearest centroid\n",
        "            distances = np.zeros(n_samples)\n",
        "            for i, point in enumerate(X):\n",
        "                min_dist = float('inf')\n",
        "                for centroid in centroids:\n",
        "                    dist = np.sum((point - centroid) ** 2)\n",
        "                    min_dist = min(min_dist, dist)\n",
        "                distances[i] = min_dist\n",
        "\n",
        "            # Choose next centroid with probability proportional to distance squared\n",
        "            probabilities = distances / distances.sum()\n",
        "            next_idx = np.random.choice(n_samples, p=probabilities)\n",
        "            centroids.append(X[next_idx])\n",
        "\n",
        "        return np.array(centroids)\n",
        "\n",
        "    def _assign_clusters(self, X, centroids):\n",
        "        \"\"\"Assign each data point to the nearest centroid\"\"\"\n",
        "        distances = np.zeros((X.shape[0], self.n_clusters))\n",
        "        for k in range(self.n_clusters):\n",
        "            distances[:, k] = self._euclidean_distance(X, centroids[k])\n",
        "        return np.argmin(distances, axis=1)\n",
        "\n",
        "    def _update_centroids(self, X, labels):\n",
        "        \"\"\"Update centroids based on the mean of assigned points\"\"\"\n",
        "        new_centroids = np.zeros((self.n_clusters, X.shape[1]))\n",
        "        for k in range(self.n_clusters):\n",
        "            cluster_points = X[labels == k]\n",
        "            if len(cluster_points) > 0:\n",
        "                new_centroids[k] = cluster_points.mean(axis=0)\n",
        "            else:\n",
        "                # If cluster is empty, reinitialize with random point\n",
        "                new_centroids[k] = X[np.random.randint(X.shape[0])]\n",
        "        return new_centroids\n",
        "\n",
        "    def _calculate_inertia(self, X, labels, centroids):\n",
        "        \"\"\"Calculate within-cluster sum of squares (inertia)\"\"\"\n",
        "        inertia = 0\n",
        "        for k in range(self.n_clusters):\n",
        "            cluster_points = X[labels == k]\n",
        "            if len(cluster_points) > 0:\n",
        "                inertia += np.sum((cluster_points - centroids[k]) ** 2)\n",
        "        return inertia\n",
        "\n",
        "    def _single_run(self, X):\n",
        "        \"\"\"Perform a single run of K-Means\"\"\"\n",
        "        # Initialize centroids\n",
        "        if self.init == 'kmeans++':\n",
        "            centroids = self._initialize_centroids_kmeans_plus_plus(X)\n",
        "        else:\n",
        "            centroids = self._initialize_centroids_random(X)\n",
        "\n",
        "        history = [centroids.copy()]\n",
        "\n",
        "        for iteration in range(self.max_iters):\n",
        "            # Assign clusters\n",
        "            labels = self._assign_clusters(X, centroids)\n",
        "\n",
        "            # Update centroids\n",
        "            new_centroids = self._update_centroids(X, labels)\n",
        "            history.append(new_centroids.copy())\n",
        "\n",
        "            # Check for convergence\n",
        "            centroid_shift = np.sum((new_centroids - centroids) ** 2)\n",
        "            if centroid_shift < self.tol:\n",
        "                break\n",
        "\n",
        "            centroids = new_centroids\n",
        "\n",
        "        inertia = self._calculate_inertia(X, labels, centroids)\n",
        "        return centroids, labels, inertia, iteration + 1, history\n",
        "\n",
        "    def fit(self, X):\n",
        "        \"\"\"\n",
        "        Fit the K-Means model to data X\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            Training data\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        self : object\n",
        "            Fitted estimator\n",
        "        \"\"\"\n",
        "        if self.random_state is not None:\n",
        "            np.random.seed(self.random_state)\n",
        "\n",
        "        X = np.array(X)\n",
        "\n",
        "        best_inertia = float('inf')\n",
        "        best_centroids = None\n",
        "        best_labels = None\n",
        "        best_n_iter = None\n",
        "        best_history = None\n",
        "\n",
        "        # Run n_init times and keep the best result\n",
        "        for _ in range(self.n_init):\n",
        "            centroids, labels, inertia, n_iter, history = self._single_run(X)\n",
        "            if inertia < best_inertia:\n",
        "                best_inertia = inertia\n",
        "                best_centroids = centroids\n",
        "                best_labels = labels\n",
        "                best_n_iter = n_iter\n",
        "                best_history = history\n",
        "\n",
        "        self.centroids = best_centroids\n",
        "        self.labels_ = best_labels\n",
        "        self.inertia_ = best_inertia\n",
        "        self.n_iter_ = best_n_iter\n",
        "        self.history = best_history\n",
        "\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"\n",
        "        Predict the closest cluster for each sample in X\n",
        "\n",
        "        Parameters:\n",
        "        -----------\n",
        "        X : array-like of shape (n_samples, n_features)\n",
        "            New data to predict\n",
        "\n",
        "        Returns:\n",
        "        --------\n",
        "        labels : array of shape (n_samples,)\n",
        "            Index of the cluster each sample belongs to\n",
        "        \"\"\"\n",
        "        if self.centroids is None:\n",
        "            raise ValueError(\"Model not fitted. Call fit() first.\")\n",
        "        return self._assign_clusters(np.array(X), self.centroids)\n",
        "\n",
        "    def fit_predict(self, X):\n",
        "        \"\"\"Fit the model and return cluster labels\"\"\"\n",
        "        self.fit(X)\n",
        "        return self.labels_\n",
        "\n",
        "print(\"KMeansFromScratch class defined successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph8Xs48O3IRG"
      },
      "source": [
        "## 3. Generate Synthetic Data for Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RjCZuJmE3IRH"
      },
      "outputs": [],
      "source": [
        "# Generate synthetic clustered data\n",
        "X_synthetic, y_true = make_blobs(n_samples=500, centers=4, cluster_std=0.8,\n",
        "                                  n_features=2, random_state=42)\n",
        "\n",
        "# Visualize the synthetic data\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(X_synthetic[:, 0], X_synthetic[:, 1], c=y_true, cmap='viridis',\n",
        "            alpha=0.6, edgecolors='k', s=50)\n",
        "plt.xlabel('Feature 1')\n",
        "plt.ylabel('Feature 2')\n",
        "plt.title('Synthetic Data with 4 Clusters (Ground Truth)')\n",
        "plt.colorbar(label='True Cluster')\n",
        "plt.show()\n",
        "\n",
        "print(f\"Dataset shape: {X_synthetic.shape}\")\n",
        "print(f\"Number of true clusters: {len(np.unique(y_true))}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElwvAd5E3IRH"
      },
      "source": [
        "## 4. Apply Our K-Means Implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I7RtyvOJ3IRH"
      },
      "outputs": [],
      "source": [
        "# Fit our K-Means implementation\n",
        "kmeans_scratch = KMeansFromScratch(n_clusters=4, init='kmeans++',\n",
        "                                    max_iters=300, random_state=42)\n",
        "labels_scratch = kmeans_scratch.fit_predict(X_synthetic)\n",
        "\n",
        "print(f\"Number of iterations: {kmeans_scratch.n_iter_}\")\n",
        "print(f\"Inertia (WCSS): {kmeans_scratch.inertia_:.4f}\")\n",
        "print(f\"Final centroids shape: {kmeans_scratch.centroids.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZrfXHoE3IRI"
      },
      "outputs": [],
      "source": [
        "# Visualize clustering results\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Plot 1: Our implementation results\n",
        "scatter1 = axes[0].scatter(X_synthetic[:, 0], X_synthetic[:, 1], c=labels_scratch,\n",
        "                           cmap='viridis', alpha=0.6, edgecolors='k', s=50)\n",
        "axes[0].scatter(kmeans_scratch.centroids[:, 0], kmeans_scratch.centroids[:, 1],\n",
        "                c='red', marker='X', s=300, edgecolors='black', linewidths=2,\n",
        "                label='Centroids')\n",
        "axes[0].set_xlabel('Feature 1')\n",
        "axes[0].set_ylabel('Feature 2')\n",
        "axes[0].set_title('K-Means from Scratch - Clustering Results')\n",
        "axes[0].legend()\n",
        "\n",
        "# Plot 2: Compare with sklearn\n",
        "sklearn_kmeans = SklearnKMeans(n_clusters=4, init='k-means++', random_state=42, n_init=10)\n",
        "labels_sklearn = sklearn_kmeans.fit_predict(X_synthetic)\n",
        "\n",
        "scatter2 = axes[1].scatter(X_synthetic[:, 0], X_synthetic[:, 1], c=labels_sklearn,\n",
        "                           cmap='viridis', alpha=0.6, edgecolors='k', s=50)\n",
        "axes[1].scatter(sklearn_kmeans.cluster_centers_[:, 0], sklearn_kmeans.cluster_centers_[:, 1],\n",
        "                c='red', marker='X', s=300, edgecolors='black', linewidths=2,\n",
        "                label='Centroids')\n",
        "axes[1].set_xlabel('Feature 1')\n",
        "axes[1].set_ylabel('Feature 2')\n",
        "axes[1].set_title('Sklearn K-Means - Clustering Results')\n",
        "axes[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDkcB3Od3IRI"
      },
      "source": [
        "## 5. Visualize the Convergence Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Thk9J9EK3IRI"
      },
      "outputs": [],
      "source": [
        "# Create a fresh instance to visualize convergence\n",
        "kmeans_viz = KMeansFromScratch(n_clusters=4, init='random', max_iters=20,\n",
        "                                n_init=1, random_state=42)\n",
        "kmeans_viz.fit(X_synthetic)\n",
        "\n",
        "# Visualize convergence step by step\n",
        "n_steps = min(6, len(kmeans_viz.history))\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
        "axes = axes.flatten()\n",
        "\n",
        "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
        "\n",
        "for i, ax in enumerate(axes):\n",
        "    if i < n_steps:\n",
        "        centroids = kmeans_viz.history[i]\n",
        "        # Calculate labels for this step\n",
        "        distances = np.zeros((X_synthetic.shape[0], 4))\n",
        "        for k in range(4):\n",
        "            distances[:, k] = np.sqrt(np.sum((X_synthetic - centroids[k]) ** 2, axis=1))\n",
        "        labels = np.argmin(distances, axis=1)\n",
        "\n",
        "        for k in range(4):\n",
        "            cluster_points = X_synthetic[labels == k]\n",
        "            ax.scatter(cluster_points[:, 0], cluster_points[:, 1],\n",
        "                      c=colors[k], alpha=0.5, s=30, label=f'Cluster {k}')\n",
        "\n",
        "        ax.scatter(centroids[:, 0], centroids[:, 1], c='black',\n",
        "                  marker='X', s=200, edgecolors='white', linewidths=2)\n",
        "        ax.set_title(f'Iteration {i}')\n",
        "        ax.set_xlabel('Feature 1')\n",
        "        ax.set_ylabel('Feature 2')\n",
        "    else:\n",
        "        ax.axis('off')\n",
        "\n",
        "plt.suptitle('K-Means Convergence Visualization', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vliJzatv3IRI"
      },
      "source": [
        "## 6. Elbow Method for Optimal K Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFgrX1wK3IRI"
      },
      "outputs": [],
      "source": [
        "# Find optimal number of clusters using Elbow Method\n",
        "K_range = range(1, 11)\n",
        "inertias_scratch = []\n",
        "inertias_sklearn = []\n",
        "\n",
        "for k in K_range:\n",
        "    # Our implementation\n",
        "    km_scratch = KMeansFromScratch(n_clusters=k, init='kmeans++', random_state=42)\n",
        "    km_scratch.fit(X_synthetic)\n",
        "    inertias_scratch.append(km_scratch.inertia_)\n",
        "\n",
        "    # Sklearn for comparison\n",
        "    km_sklearn = SklearnKMeans(n_clusters=k, init='k-means++', random_state=42, n_init=10)\n",
        "    km_sklearn.fit(X_synthetic)\n",
        "    inertias_sklearn.append(km_sklearn.inertia_)\n",
        "\n",
        "# Plot Elbow curves\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "ax.plot(K_range, inertias_scratch, 'bo-', label='Our Implementation', linewidth=2, markersize=8)\n",
        "ax.plot(K_range, inertias_sklearn, 'rs--', label='Sklearn', linewidth=2, markersize=8)\n",
        "ax.set_xlabel('Number of Clusters (K)', fontsize=12)\n",
        "ax.set_ylabel('Inertia (Within-Cluster Sum of Squares)', fontsize=12)\n",
        "ax.set_title('Elbow Method for Optimal K', fontsize=14, fontweight='bold')\n",
        "ax.legend(fontsize=10)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_xticks(K_range)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nThe 'elbow' in the curve suggests the optimal number of clusters.\")\n",
        "print(\"In this case, K=4 appears to be optimal (matching our ground truth).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhMq1hIk3IRI"
      },
      "source": [
        "## 7. Clustering Quality Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "45NfiXP13IRJ"
      },
      "outputs": [],
      "source": [
        "def calculate_clustering_metrics(X, labels):\n",
        "    \"\"\"\n",
        "    Calculate various clustering quality metrics\n",
        "\n",
        "    Metrics:\n",
        "    - Silhouette Score: Measures how similar an object is to its own cluster compared to other clusters\n",
        "      Range: [-1, 1], higher is better\n",
        "    - Calinski-Harabasz Index: Ratio of between-cluster dispersion to within-cluster dispersion\n",
        "      Higher is better\n",
        "    - Davies-Bouldin Index: Average similarity between each cluster and its most similar cluster\n",
        "      Lower is better\n",
        "    \"\"\"\n",
        "    metrics = {}\n",
        "\n",
        "    if len(np.unique(labels)) > 1:\n",
        "        metrics['Silhouette Score'] = silhouette_score(X, labels)\n",
        "        metrics['Calinski-Harabasz Index'] = calinski_harabasz_score(X, labels)\n",
        "        metrics['Davies-Bouldin Index'] = davies_bouldin_score(X, labels)\n",
        "    else:\n",
        "        metrics['Silhouette Score'] = np.nan\n",
        "        metrics['Calinski-Harabasz Index'] = np.nan\n",
        "        metrics['Davies-Bouldin Index'] = np.nan\n",
        "\n",
        "    return metrics\n",
        "\n",
        "# Calculate metrics for different K values\n",
        "print(\"Clustering Quality Metrics for Different K Values:\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "metrics_data = []\n",
        "for k in range(2, 8):\n",
        "    km = KMeansFromScratch(n_clusters=k, init='kmeans++', random_state=42)\n",
        "    labels = km.fit_predict(X_synthetic)\n",
        "    metrics = calculate_clustering_metrics(X_synthetic, labels)\n",
        "    metrics['K'] = k\n",
        "    metrics['Inertia'] = km.inertia_\n",
        "    metrics_data.append(metrics)\n",
        "\n",
        "metrics_df = pd.DataFrame(metrics_data)\n",
        "metrics_df = metrics_df[['K', 'Inertia', 'Silhouette Score', 'Calinski-Harabasz Index', 'Davies-Bouldin Index']]\n",
        "print(metrics_df.to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"\\nInterpretation:\")\n",
        "print(\"• Silhouette Score: Higher is better (max = 1)\")\n",
        "print(\"• Calinski-Harabasz Index: Higher is better\")\n",
        "print(\"• Davies-Bouldin Index: Lower is better\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vEgnYQ_93IRJ"
      },
      "outputs": [],
      "source": [
        "# Visualize metrics\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "# Silhouette Score\n",
        "axes[0].plot(metrics_df['K'], metrics_df['Silhouette Score'], 'go-', linewidth=2, markersize=8)\n",
        "axes[0].set_xlabel('Number of Clusters (K)')\n",
        "axes[0].set_ylabel('Silhouette Score')\n",
        "axes[0].set_title('Silhouette Score vs K')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Calinski-Harabasz Index\n",
        "axes[1].plot(metrics_df['K'], metrics_df['Calinski-Harabasz Index'], 'bo-', linewidth=2, markersize=8)\n",
        "axes[1].set_xlabel('Number of Clusters (K)')\n",
        "axes[1].set_ylabel('Calinski-Harabasz Index')\n",
        "axes[1].set_title('Calinski-Harabasz Index vs K')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "# Davies-Bouldin Index\n",
        "axes[2].plot(metrics_df['K'], metrics_df['Davies-Bouldin Index'], 'ro-', linewidth=2, markersize=8)\n",
        "axes[2].set_xlabel('Number of Clusters (K)')\n",
        "axes[2].set_ylabel('Davies-Bouldin Index')\n",
        "axes[2].set_title('Davies-Bouldin Index vs K')\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jy4r-b4K3IRJ"
      },
      "source": [
        "## 8. Real Dataset: Iris Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1aLthnWL3IRJ"
      },
      "outputs": [],
      "source": [
        "# Load Iris dataset\n",
        "iris = load_iris()\n",
        "X_iris = iris.data\n",
        "y_iris = iris.target\n",
        "feature_names = iris.feature_names\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_iris_scaled = scaler.fit_transform(X_iris)\n",
        "\n",
        "print(f\"Iris dataset shape: {X_iris.shape}\")\n",
        "print(f\"Features: {feature_names}\")\n",
        "print(f\"Number of species (true clusters): {len(np.unique(y_iris))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_bxCKGE3IRJ"
      },
      "outputs": [],
      "source": [
        "# Apply K-Means to Iris dataset\n",
        "kmeans_iris = KMeansFromScratch(n_clusters=3, init='kmeans++', random_state=42)\n",
        "labels_iris = kmeans_iris.fit_predict(X_iris_scaled)\n",
        "\n",
        "# Visualize results (using first two principal components via simple projection)\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# True labels\n",
        "scatter1 = axes[0].scatter(X_iris[:, 0], X_iris[:, 1], c=y_iris, cmap='viridis',\n",
        "                           alpha=0.7, edgecolors='k', s=60)\n",
        "axes[0].set_xlabel(feature_names[0])\n",
        "axes[0].set_ylabel(feature_names[1])\n",
        "axes[0].set_title('Iris Dataset - True Species Labels')\n",
        "\n",
        "# K-Means labels\n",
        "scatter2 = axes[1].scatter(X_iris[:, 0], X_iris[:, 1], c=labels_iris, cmap='viridis',\n",
        "                           alpha=0.7, edgecolors='k', s=60)\n",
        "axes[1].set_xlabel(feature_names[0])\n",
        "axes[1].set_ylabel(feature_names[1])\n",
        "axes[1].set_title('Iris Dataset - K-Means Clustering (K=3)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate metrics for Iris clustering\n",
        "iris_metrics = calculate_clustering_metrics(X_iris_scaled, labels_iris)\n",
        "print(\"\\nClustering Quality Metrics for Iris Dataset:\")\n",
        "for metric, value in iris_metrics.items():\n",
        "    print(f\"  {metric}: {value:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKbMuhpr3IRJ"
      },
      "source": [
        "## 9. Comparison: Random vs K-Means++ Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qgPbwc_3IRJ"
      },
      "outputs": [],
      "source": [
        "# Compare initialization methods\n",
        "n_runs = 50\n",
        "inertias_random = []\n",
        "inertias_kmeanspp = []\n",
        "iters_random = []\n",
        "iters_kmeanspp = []\n",
        "\n",
        "for i in range(n_runs):\n",
        "    # Random initialization\n",
        "    km_random = KMeansFromScratch(n_clusters=4, init='random', n_init=1, random_state=i)\n",
        "    km_random.fit(X_synthetic)\n",
        "    inertias_random.append(km_random.inertia_)\n",
        "    iters_random.append(km_random.n_iter_)\n",
        "\n",
        "    # K-Means++ initialization\n",
        "    km_kmeanspp = KMeansFromScratch(n_clusters=4, init='kmeans++', n_init=1, random_state=i)\n",
        "    km_kmeanspp.fit(X_synthetic)\n",
        "    inertias_kmeanspp.append(km_kmeanspp.inertia_)\n",
        "    iters_kmeanspp.append(km_kmeanspp.n_iter_)\n",
        "\n",
        "# Visualize comparison\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Inertia comparison\n",
        "axes[0].boxplot([inertias_random, inertias_kmeanspp], labels=['Random', 'K-Means++'])\n",
        "axes[0].set_ylabel('Inertia')\n",
        "axes[0].set_title('Inertia Distribution by Initialization Method')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Iterations comparison\n",
        "axes[1].boxplot([iters_random, iters_kmeanspp], labels=['Random', 'K-Means++'])\n",
        "axes[1].set_ylabel('Number of Iterations')\n",
        "axes[1].set_title('Convergence Speed by Initialization Method')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nStatistics:\")\n",
        "print(f\"Random Init - Mean Inertia: {np.mean(inertias_random):.2f} ± {np.std(inertias_random):.2f}\")\n",
        "print(f\"K-Means++ Init - Mean Inertia: {np.mean(inertias_kmeanspp):.2f} ± {np.std(inertias_kmeanspp):.2f}\")\n",
        "print(f\"\\nRandom Init - Mean Iterations: {np.mean(iters_random):.1f}\")\n",
        "print(f\"K-Means++ Init - Mean Iterations: {np.mean(iters_kmeanspp):.1f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsPBSWGw3IRK"
      },
      "source": [
        "## 10. Silhouette Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvN-mLzS3IRK"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import silhouette_samples\n",
        "\n",
        "# Calculate silhouette scores for each sample\n",
        "kmeans_final = KMeansFromScratch(n_clusters=4, init='kmeans++', random_state=42)\n",
        "labels_final = kmeans_final.fit_predict(X_synthetic)\n",
        "silhouette_vals = silhouette_samples(X_synthetic, labels_final)\n",
        "\n",
        "# Create silhouette plot\n",
        "fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "y_lower = 10\n",
        "colors = plt.cm.viridis(np.linspace(0, 1, 4))\n",
        "\n",
        "for i in range(4):\n",
        "    cluster_silhouette_vals = silhouette_vals[labels_final == i]\n",
        "    cluster_silhouette_vals.sort()\n",
        "\n",
        "    cluster_size = len(cluster_silhouette_vals)\n",
        "    y_upper = y_lower + cluster_size\n",
        "\n",
        "    ax.fill_betweenx(np.arange(y_lower, y_upper), 0, cluster_silhouette_vals,\n",
        "                     facecolor=colors[i], edgecolor=colors[i], alpha=0.7)\n",
        "    ax.text(-0.05, y_lower + 0.5 * cluster_size, str(i))\n",
        "\n",
        "    y_lower = y_upper + 10\n",
        "\n",
        "# Add average silhouette score line\n",
        "avg_silhouette = np.mean(silhouette_vals)\n",
        "ax.axvline(x=avg_silhouette, color='red', linestyle='--',\n",
        "           label=f'Average Silhouette Score: {avg_silhouette:.3f}')\n",
        "\n",
        "ax.set_xlabel('Silhouette Coefficient')\n",
        "ax.set_ylabel('Cluster')\n",
        "ax.set_title('Silhouette Analysis for K-Means Clustering (K=4)')\n",
        "ax.legend(loc='upper right')\n",
        "ax.set_xlim([-0.1, 1])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHKpLQjz3IRK"
      },
      "source": [
        "## 11. Summary and Conclusions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kJ7ne8R63IRK"
      },
      "outputs": [],
      "source": [
        "print(\"=\"*70)\n",
        "print(\"K-MEANS CLUSTERING FROM SCRATCH - SUMMARY\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "print(\"\\n1. ALGORITHM IMPLEMENTED:\")\n",
        "print(\"   - K-Means clustering with both random and K-Means++ initialization\")\n",
        "print(\"   - Support for multiple initializations (n_init parameter)\")\n",
        "print(\"   - Convergence detection based on centroid movement\")\n",
        "\n",
        "print(\"\\n2. KEY FEATURES:\")\n",
        "print(\"   - fit(), predict(), and fit_predict() methods\")\n",
        "print(\"   - Inertia calculation (within-cluster sum of squares)\")\n",
        "print(\"   - History tracking for visualization\")\n",
        "\n",
        "print(\"\\n3. CLUSTERING QUALITY METRICS USED:\")\n",
        "print(\"   - Silhouette Score: Measures cluster cohesion and separation\")\n",
        "print(\"   - Calinski-Harabasz Index: Ratio of between/within cluster variance\")\n",
        "print(\"   - Davies-Bouldin Index: Average cluster similarity measure\")\n",
        "print(\"   - Inertia/WCSS: Within-cluster sum of squares\")\n",
        "\n",
        "print(\"\\n4. DATASETS TESTED:\")\n",
        "print(\"   - Synthetic blob data (4 clusters, 500 samples)\")\n",
        "print(\"   - Iris dataset (3 species, 150 samples)\")\n",
        "\n",
        "print(\"\\n5. KEY FINDINGS:\")\n",
        "print(f\"   - K-Means++ initialization provides better and more consistent results\")\n",
        "print(f\"   - Elbow method correctly identified K=4 for synthetic data\")\n",
        "print(f\"   - Our implementation matches sklearn's K-Means performance\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uBTrRWh33IRK"
      },
      "source": [
        "## References\n",
        "\n",
        "1. Arthur, D., & Vassilvitskii, S. (2007). k-means++: The advantages of careful seeding. SODA '07.\n",
        "2. MacQueen, J. (1967). Some methods for classification and analysis of multivariate observations. Berkeley Symposium on Mathematical Statistics and Probability.\n",
        "3. VanderPlas, J. (2016). Python Data Science Handbook. O'Reilly Media.\n",
        "4. Scikit-learn documentation: https://scikit-learn.org/stable/modules/clustering.html#k-means"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}